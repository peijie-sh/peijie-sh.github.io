<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[JDK默认使用的垃圾回收器]]></title>
      <url>%2F2018%2F09%2F09%2FJDK%E9%BB%98%E8%AE%A4%E4%BD%BF%E7%94%A8%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
      <content type="text"><![CDATA[查看方法 java -XX:+PrintCommandLineFlags -version 引用《深入理解Java虚拟机：JVM高级特性与最佳实践》的介绍： 所以，jdk8环境下，默认使用 Parallel Scavenge（新生代）+ Serial Old（老年代） -XX:+PrintCommandLineFlagsjvm参数可查看默认设置收集器类型 -XX:+PrintGCDetails亦可通过打印的GC日志的新生代、老年代名称判断]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（七）：垃圾回收器]]></title>
      <url>%2F2018%2F06%2F29%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
      <content type="text"><![CDATA[一些概念并行（Parallel）指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。 吞吐量CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）。虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 HotSpot虚拟机的垃圾回收器Serial 最基本的单线程垃圾收集器。使用一个CPU或一条收集线程去执行垃圾收集工作。 工作时会Stop The World，暂停所有用户线程，造成卡顿。适合运行在Client模式下的虚拟机。 用作新生代收集器，复制算法。 ParNew Serial收集器的多线程版本，和Serial的唯一区别就是使用了多条线程去垃圾收集。 除了Serial，只有它可以和CMS搭配使用的收集器。 用作新生代收集器，复制算法。 Parallel Scavenge 用作新生代收集器，复制算法。 关注高吞吐量，可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。 Serial Old Serial收集器的老年代版本，单线程，标记-整理 算法。 一般用于Client模式的虚拟机。 当虚拟机是Server模式时，有2个用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用 ，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。 Parallel Old Parallel Scavenge收集器的老年代版本，使用多线程和 标记-整理 算法。在JDK 1.6中开始提供。 在注重吞吐量的场合，配合Parallel Scavenge收集器使用。 CMS（Concurrent Mark Sweep） 一种以获取最短回收停顿时间为目标的收集器。适合需要与用户交互的程序，良好的响应速度能提升用户体验。 基于 标记—清除 算法。适合作为老年代收集器。 收集过程分4步： 初始标记（CMS initial mark）：只是标记一下GC Roots能直接关联到的对象，速度很快，会Stop The World。 并发标记（CMS concurrent mark）：进行GC Roots Tracing（可达性分析）的过程。 重新标记（CMS remark）：会Stop The World。为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般比初始标记阶段稍长些，但远比并发标记的时间短。 并发清除（CMS concurrent sweep）：回收内存。 耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以是并发执行的。 缺点： 并发阶段，虽然不会导致用户线程暂停，但会占用一部分线程（CPU资源），导致应用变慢，吞吐量降低。默认启动收集线程数是（CPU数量+3）/4。即当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大。 无法清除浮动垃圾。并发清除阶段，用户线程还在运行，还会产生新垃圾。这些垃圾不会在此次GC中被标记，只能等到下次GC被回收。 标记-清除 算法会产生大量不连续内存，导致分配大对象时内存不够，提前触发Full GC。 G1 在JDK1.7提供的先进垃圾收集器。 既适合新生代，也适合老年代。 空间整合：使用 标记-整理 算法，不产生碎片空间。 整个Java堆被分为多个大小相同的的块（region）。新生代和老年代不再是物理隔离的，而是一部分region块组成的集合。 默认把堆平均分成2048个region，最小1M，最大32M，必须是2的幂次方，可以通过-XX:G1HeapRegionSize参数指定。region分为4种： E：eden区，新生代 S：survivor区，新生代 O：old区，老年代 H：humongous区，用来放大对象。当新建对象大小超过region大小一半时，直接在新的一个或多个连续region中分配，并标记为H 可预测的停顿时间：估算每个region内的垃圾可回收的空间以及回收需要的时间（经验值），记录在一个优先列表中。收集时，优先回收价值最大的region，而不是在整个堆进行全区域回收。这样提高了回收效率，得名：Garbage-First。 G1中有2种GC： young GC：新生代eden区没有足够可用空间时触发。存活的对象移到survivor区或晋升old区。 mixed GC：当old区对象很多时，老年代对象空间占堆总空间的比值达到阈值（-XX:InitiatingHeapOccupancyPercent默认45%）会触发，它除了回收年轻代，也回收 部分 老年代（回收价值高的部分region）。 mixed GC回收步骤： 初始标记（Initial Marking）：只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象。这阶段需要停顿线程（STW），但耗时很短，共用YGC的停顿，所以一般伴随着YGC发生。 并发标记（Concurrent Marking）：进行可达性分析，找出存活对象，耗时长，但可与用户线程并发执行。 最终标记（Final Marking）：修正并发标记阶段用户线程运行导致的变动记录。会STW，但可以并行执行，时间不会很长。 筛选回收（Live Data Counting and Evacuation）：根据每个region的回收价值和回收成本排序，根据用户配置的GC停顿时间开始回收。 当对象分配过快，mixed GC来不及回收，G1会退化，触发Full GC，它使用单线程的Serial收集器来回收，整个过程STW，要尽量避免这种情况。 当内存很少的时候（存活对象占用大量空间），没有足够空间来复制对象，会导致回收失败。这时会保留被移动过的对象和没移动的对象，只调整引用。失败发生后，收集器认为存活对象被移动了，有足够空间让应用程序使用，于是用户线程继续工作，等待下一次触发GC。如果内存不够，就会触发Full GC。 参考G1的详细介绍]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（六）：线程安全和锁优化]]></title>
      <url>%2F2018%2F06%2F27%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%92%8C%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[线程安全的实现方法互斥同步互斥是因，同步是果；互斥是方法，同步是目的。 synchronized关键字 synchronized关键字是基本的互斥同步手段。它在编译后会在同步代码块前后加入2条字节码指令：monitorenter和monitorexit。 这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized指定了对象参数，那就是这个对象的reference；如果没有指定，就根据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。 执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，或当前线程已经拥有了那个对象的锁，把锁的计数器加1；在执行monitorexit指令时会将锁计数器减1。当计数器为0时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。 synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。 同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。 Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间，所以synchronized是Java语言中一个重量级的操作。不过虚拟机会有一些优化措施，比如自旋等待。 ReentrantLock重入锁重入锁位于java.util.concurrent包。基本用法和synchronized相似，只是代码写法有区别：synchronized是原生语法层面的实现。ReentrantLock是API层面，使用lock()和unlock()方法配合try/finally语句块来实现。 重入锁有3个高级特性： 等待可中断：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。 可实现公平锁：公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。 锁可以绑定多个条件：一个ReentrantLock对象可以同时绑定多个Condition对象，而在synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无须这样做，只需要多次调用newCondition()方法即可。 性能比较 JDK1.6之前，在多线程环境下，synchronized的吞吐量随着处理器数量增加而下降得非常严重。 JDK1.6之后，虚拟机做了优化，2种方式性能差不多。推荐优先使用synchronized方式。 非阻塞同步互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步（Blocking Synchronization）。 按处理问题的方式来说： 互斥同步是悲观并发策略：无论是否产生共享数据争用，都会做同步措施（加锁，用户态内核态转换等）。 非阻塞同步是一种乐观并发策略：它基于冲突检测。通俗的说，就是先执行代码，若没有发生共享数据争用，就成功执行；若发生共享数据争用，就采取补偿措施（比如不断重试，直到成功），这种策略不会导致线程阻塞。 CAS操作：CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，这个处理过程是个原子操作。 ABA问题：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。 无同步方案如果一个方法本来就不涉及共享数据，那它就无须任何同步措施去保证正确性。 可重入代码：这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。 线程本地存储：一段代码中所需要的数据必须与其他代码共享，并且可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”；如果一个变量要被某个线程独享，Java中就没有类似C++中__declspec（thread） 这样的关键字，不过还是可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。 锁优化适应性自旋（Adaptive Spinning）线程阻塞的时候，让等待的线程不放弃cpu执行时间，而是执行一个自旋(一般是空循环)，这叫做自旋锁。 自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，带来性能上的浪费。 因此，自旋等待的时间必须要有一定的限度。如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX：PreBlockSpin来更改。 JDK1.6引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。比如前一次自旋了3次就获得了一个锁，那么下一次虚拟机会允许他自旋更多次来获得这个锁。如果一个锁很少能通过自旋成功获得，那么之后再遇到这个情况就会省略自旋过程了。 锁消除（Lock Elimination）虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。一般根据逃逸分析的数据支持来作为判定依据。 锁粗化（Lock Coarsening）原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。 但如果一系列操作频繁对同一个对象加锁解锁，或者加锁操作再循环体内，会耗费性能，这时虚拟机会扩大加锁范围。 轻量级锁（Lightweight Locking）轻量级锁是JDK 1.6之中加入的新型锁机制。它的作用是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 HotSpot虚拟机的对象头（Object Header）分为两部分信息，第一部分用于存储对象自身的运行时数据，这部分称为Mark Word。还有一部分存储指向方法区对象类型数据的指针。 加锁在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word）。然后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后2bit）将转变为“00”，即表示此对象处于轻量级锁定状态。如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 解锁解锁过程也是通过CAS操作来进行的。如果对象的Mark Word仍然指向着线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来，如果替换成功，整个同步过程就完成了。如果替换失败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。 性能没有锁竞争时，轻量级锁用CAS操作替代互斥量的开销，性能较优。有锁竞争时，除了互斥量开销，还有CAS操作开销，所以性能较差。但是，一般情况下，在整个同步周期内都是不存在竞争的”，这是一个经验数据。 偏向锁（Biased Locking）偏向锁也是JDK1.6中引入的锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。 当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作。当有另外一个线程去尝试获取这个锁时，偏向模式结束。 偏向锁可以提高带有同步但无竞争的程序性能，但并不一定总是对程序运行有利。如果程序中大多数的锁总是被多个不同的线程访问，那偏向模式就是多余的。在具体问题具体分析的前提下，有时候使用参数-XX：-UseBiasedLocking来禁止偏向锁优化反而可以提升性能。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（五）：Java内存模型与线程]]></title>
      <url>%2F2018%2F06%2F26%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9AJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[Java内存模型JMM(Java Memory Model)是JVM定义的内存模型，用来屏蔽各种硬件和操作系统的内存访问差异。 主内存：所有的变量都存储在主内存（Main Memory，类比物理内存）中。 工作内存：每条线程有自己的工作内存（Working Memory，类比处理器高速缓存），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 内存间的交互操作 lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 其中read和load，store和write必须成对使用，顺序但补一定连续的执行。通俗的说，就是执行了read，后面一定会执行load，但不一定read之后立马load；store和write也一样。lock和unlock也是成对出现，一个变量在同一时间点只能有一个线程对其进行lock。 对于普通变量的操作：创建变量，是在主内存中初始化。线程用到的变量，会先从主内存中拷贝(read)出来，加载(load)到工作内存，然后引用(use)变量并运算赋值(assign)。然后存储(store)到工作内存，然后更新(write)掉原来的变量。 普通变量的值在线程间传递均需要通过主内存来完成。例如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线程A回写完成了之后再从主内存进行读取操作，新变量值才会对线程B可见。 对于volatile修饰的变量:过程和普通变量一样。但保证变量对所有线程的可见性，并且会禁止指令重排序的优化。 volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。 先行发生原则(happens-before)它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题。 先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 线程线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度（线程是CPU调度的基本单位）。 实现线程的3种方式： 使用内核线程实现 内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（Multi-Threads Kernel）。 程序一般不直接使用内核线程，而是轻量级进程（通俗意义上的线程）。此2者1:1对应关系。创建，调用同步等都由系统执行，代价较高（需要在内核态和用户态之间来回切换），每个轻量级进程会消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持的轻量级进程时有限的。 使用用户线程实现 广义来说，一个线程只要不是内核线程，就可以认为是用户线程。因此，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制。 狭义的说，用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1:N的关系称为一对多的线程模型。 使用用户线程的优势在于不需要系统内核支援，劣势也是没有系统内核的支援。所有的线程操作都需要用户程序自己处理，实现会很复杂，所以现在很少使用了。 使用用户线程加轻量级进程混合实现 既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，即为N:M的关系，这种就是多对多的线程模型。 Java线程实现：JDK1.2之前是用户线程，1.2和之后的版本，使用操作系统原生线程模型（内核线程）。 Java线程调度线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种： 协同式线程调度（Cooperative Threads-Scheduling）：线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。 好处：实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。 坏处：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。 抢占式线程调度（Preemptive Threads-Scheduling）：每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定（在Java中，Thread.yield()可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法的）。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度 。 虽然Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配一点执行时间，另外的线程少分配一点——通过设置线程优先级的方式(两个线程同时处于Ready状态时，优先级越高的线程越容易被系统选择执行)，不过这方法不是很可靠，因为系统线程优先级和Java的10种线程优先级不一定一一对应。 线程状态在任意时间点，一个线程只有一种状态 新建(New)：创建后尚未启动 运行(Runable)：正在执行或正在等待CPU为它分配执行时间 等待(Waiting)： 无限等待(Waiting)：线程不会被分配CPU执行时间，等待被其他线程显式地唤醒。 期限等待(Timed Waiting)：线程不会被分配CPU执行时间，无须等待被其他线程显式地唤醒，在一定时间后它们会由系统自动唤醒。 阻塞(Blocked)：被阻塞 阻塞和等待的区别：阻塞状态在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而等待状态则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。 结束(Terminated)：已终止]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring的事件机制]]></title>
      <url>%2F2018%2F06%2F15%2FSpring%E7%9A%84%E4%BA%8B%E4%BB%B6%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[当把一个事件发布到Spring提供的ApplicationContext中，被监听器侦测到，就会执行对应的处理方法。 事件本身事件是一个自定义的类，需要继承Spring提供的ApplicationEvent。123456789@Datapublic class MyEvent extends ApplicationEvent &#123; private String msg; public MyEvent(Object source, String msg) &#123; super(source); this.msg = msg; &#125;&#125; 事件监听基本方法是实现ApplicationListener接口，自定义一个监听器，实现onApplicationEvent()方法，然后添加到ApplicationContext。比如：1234567891011121314public class MyListener implements ApplicationListener&lt;MyEvent&gt; &#123; @Override public void onApplicationEvent(MyEvent event) &#123; System.out.print("监听到MyEvent事件"); &#125; &#125; ...// SpringBoot的启动类中添加监听器 public static void main(String[] args) &#123; SpringApplication application = new SpringApplication(MyApplication.class); application.addListeners(new MyListener()); application.run(args); &#125; 也可以使用注解@EventListener（推荐）：原理就是通过扫描这个注解，创建监听器并添加到ApplicationContext。12345678910111213141516@Component@Slf4jpublic class MyEventHandler &#123; @EventListener public void handleEvent(MyEvent event) &#123; log.info("------------处理事件：&#123;&#125;", event.getMsg()); try &#123; Thread.sleep(5 * 1000L); log.info("事件1(5s)处理完成"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 事件发布可以通过上下文对象的发布方法ConfigurableApplicationContext::publishEvent()来发布。也可以实现ApplicationEventPublisherAware接口来发布（推荐）。1234567891011121314151617@Component@Slf4jpublic class EventService implements ApplicationEventPublisherAware &#123; public ApplicationEventPublisher publisher; @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.publisher = applicationEventPublisher; &#125; public String doEventWork(String msg) &#123; log.info("------------publish event:" + msg); MyEvent event = new MyEvent(this, msg); publisher.publishEvent(event); return "OK"; &#125;&#125; 测试代码123456789101112@SpringBootTest@RunWith(SpringRunner.class)public class EventServiceTest &#123; @Autowired private EventService service; @Test public void eventTest() &#123; String msg="Java Code"; service.doEventWork(msg); &#125;&#125; 注意如果2个事件之间是继承关系，会先监听到子类事件，处理完再监听父类。12345678910111213141516171819202122232425262728// MyEvent2 extends MyEvent@Component@Slf4jpublic class MyEventHandler &#123; @EventListener public void handleEvent(MyEvent event) &#123; log.info("------------处理事件：&#123;&#125;", event.getMsg()); try &#123; Thread.sleep(5 * 1000L); log.info("事件1(5s)处理完成"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @EventListener public void handleEvent2(MyEvent2 event) &#123; log.info("------------处理事件2：&#123;&#125;", event.getMsg()); try &#123; Thread.sleep(10 * 1000L); log.info("事件2(10s)处理完成"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 当我publish一个子类事件MyEvent2时，日志如下： 注意：默认是同步事件，如要使用异步，需要在Application上开启异步，并在监听器上使用@Async]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TCP的3次握手和4次挥手过程]]></title>
      <url>%2F2018%2F04%2F09%2FTCP%E7%9A%843%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C4%E6%AC%A1%E6%8C%A5%E6%89%8B%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[建立连接（3次握手） SYN是标志位，设置SYN=1，表示请求建立连接 服务端会同时和多个客户端建立连接，所以在报文交互时，需要带上序号seq，在响应是seq+1，以此来检测报文合法性 连接过程 客户端：我想建立一个连接。状态：CLOSED -&gt; SYN SENT 服务端：可以，我同意建立连接。状态：LISTEN -&gt; SYN RCVD 客户端：好的，我收到你的确认，我准备好接收数据了。状态：SYN SENT -&gt; ESTABLISHED 服务端听到客户端准备好了，也进入准备状态。状态：SYN RCVD -&gt; ESTABLISHED 至此，TCP连接就建立完毕，开始互相发送数据了。 断开连接（4次挥手） FIN是标志位，设置FIN=1，表示请求断开连接 断开连接过程 客户端：我数据发完了，我要断开连接了。状态：ESTABLISHED -&gt; FIN WAIT 1 服务端：好，我知道你要断开连接了。状态：ESTABLISHED -&gt; CLOSE WAIT 此时，客户端确认服务端已经知道要断开了。但是，服务端可能还有数据没发送完，所以客户端还能接收数据但不会发送数据。状态：FIN WAIT 1 -&gt; FIN WAIT 2 过了一会，服务端数据发完了。 服务端：我准备好了，断开连接吧。状态：CLOSE WAIT -&gt; LAST ACK 客户端：好，那我断开连接了，再见。状态：FIN WAIT 2 -&gt; TIME WAIT 服务端：客户端已经断开了，我也断开吧。状态：LAST ACK -&gt; CLOSED 客户端等待2个MSL时间以后断开连接，状态：TIME WAIT -&gt; CLOSED TCP握手挥手的状态 状态 描述 CLOSED 关闭状态，没有连接活动或正在进行 LISTEN 监听状态，服务器正在等待连接进入 SYN SENT 已经发出连接请求，等待确认 SYN RCVD 收到一个连接请求，尚未确认 ESTABLISHED 连接建立，正常数据传输状态 FIN WAIT 1 （主动关闭）已经发送关闭请求，等待确认 FIN WAIT 2 （主动关闭）收到对方关闭确认，等待对方关闭请求 TIME WAIT 完成双向关闭，等待所有分组死掉 CLOSE WAIT （被动关闭）收到对方关闭请求，已经确认 LAST ACK （被动关闭）等待最后一个关闭确认，并等待所有分组死掉 CLOSING 双方同时尝试关闭，等待对方确认]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（四）：JVM类加载机制]]></title>
      <url>%2F2018%2F02%2F06%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9AJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[Class文件我们写的Java代码，经过编译器编译之后，就成为了.class文件，从本地机器码变成了字节码。Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符，这使得整个Class文件中存储的内容几乎全部是程序运行的必要数据，没有空隙存在。Class文件中只有2种数据结构：无符号数和表。 每个Class文件的头4个字节称为魔数（Magic Number），值为0xCAFEBABE。紧接着4个字节是Class文件的版本号。再往后，就是类的具体信息了，比如常量池、类索引、父类索引、接口索引、字段、方法等信息了。 所谓类的加载，就是把Class文件读到内存中。 类的生命周期类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）。 加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。注意，是按部就班地“开始”，而不是按部就班地“进行”或“完成”，强调这点是因为这些阶段通常都是互相交叉地混合式进行的，通常会在一个阶段执行的过程中调用、激活另外一个阶段。 加载在加载阶段，虚拟机做3件事： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 验证验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 验证阶段大致上会完成4个阶段的检验动作 文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。比如是否以魔数0xCAFEBABE开头，主、次版本号是否能被当前虚拟机处理，常量类型，指向常量的索引是否符合要求等。这阶段的验证是基于二进制字节流进行的，只有通过了这个阶段的验证后，字节流才会进入内存的方法区中进行存储，所以后面的3个验证阶段全部是基于方法区的存储结构进行的，不会再直接操作字节流。 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求。比如继承关系。 字节码验证：对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验，确保解析动作能正常执行。它发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段——解析阶段中发生。 验证阶段是非常重要的，但不是必须的。它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值。 假设一个类变量的定义为：public static int value = 123; 那变量value在准备阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器＜clinit＞()方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。 当然也有特殊情况：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值。 假设上面类变量value的定义变为：public static final int value = 123; 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化这一步开始执行类中定义的Java程序代码（或者说是字节码）。虚拟机会保证一个类的初始化方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的初始化方法，其他线程都需要阻塞等待，直到活动线程执行完毕。 JVM初始化步骤 假如这个类还没有被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句 类初始化时机只有当主动使用一个类的时候才会触发这个类的初始化，类的主动使用包括以下六种： 创建类的实例，也就是new的方式 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射，比如Class.forName(&quot;com.mysql.jdbc.Driver&quot;); 初始化某个类的子类，则其父类也会被初始化 Java虚拟机启动时被标明为启动类的类（Java Test），直接使用java.exe命令来运行某个主类 类加载器虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为“类加载器”。 双亲委派模型从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。 从Java开发人员的角度来看，类加载器可以划分为以下3种： 启动类加载器（Bootstrap ClassLoader）：负责加载存放在JAVA_HOME\lib目录中的，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。 扩展类加载器（Extension ClassLoader）：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JAVA_HOME\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）：该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承的关系来实现，而是都使用组合关系来复用父加载器的代码。它不是强制性的约束模型，而是Java设计者推荐的一种类加载器实现方式。 双亲委派模型的工作过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 ClassLoader源码分析： 123456789101112131415161718192021222324252627public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 通过分析源码，我们知道，双亲委派模型可以保证每个类都只会被加载一次（类似缓存机制）。 参考 《深入理解Java虚拟机 第二版》 纯洁的微笑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（三）：JVM命令工具]]></title>
      <url>%2F2018%2F01%2F28%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AJVM%E5%91%BD%E4%BB%A4%E5%B7%A5%E5%85%B7%2F</url>
      <content type="text"><![CDATA[jps（JVM Process Status Tool）虚拟机进程状况工具，可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（MainClass,main（）函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier,LVMID）。 命令格式：jps[options][hostid] 参数： -q：只输出LVMID，省略主类名称 -m：输出虚拟机进程启动时传给主类main()函数的参数 -l：输出主类全名，如果进程执行的时jar包则输出jar路径 -v：输出虚拟机进程启动时的jvm参数 jstat（JVM Statistics Monitoring Tool）虚拟机统计信息监视工具，用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 命令格式：jstat[option vmid[interval[s|ms][count]]] 对于命令格式中的VMID与LVMID需要特别说明一下：如果是本地虚拟机进程，VMID与LVMID是一致的；如果是远程虚拟机进程，那VMID的格式应当是：[protocol：][//]lvmid[@hostname[：port]/servername] 参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。 12// 每250毫秒查询一次进程2764垃圾收集状况，一共查询20次jstat-gc 2764 250 20 参数：主要分为3类：类装载、垃圾收集、运行期编译状况 -class：监视类装载、卸载数量、总空间和类装载消耗的时间 -gc：监视java堆状况，包括Eden区、2个Survivor区、老年代、永久代等的容量，已用空间，GC时间合计等信息 -gccapacity： 监视内容与-gc相同，但输出主要关注Java堆各个区域使用到的最大、最小空间 -gcutil：监视内容与-gc相同，但输出主要关注已使用空间占总空间的百分百 -gccause：与-gcutil一样，但会额外输出上一次GC产生的原因 -gcnew：监视新生代GC的状况 -gcnewcapacity：监视内容与-gcnew相同，输出主要关注使用到的最大、最小空间 -gcold：监视老年代GC的状况 -gcoldcapacity：监视内容与-gcold相同，输出主要关注使用到的最大、最小空间 -gcpermcapacity：输出永久代使用到的最大、最小空间 -compiler：输出JIT编译过的方法、耗时等信息 -printcompilation：输出已被JIT编译的方法 jinfo（Configuration Info for Java）Java配置信息工具，可实时查看和调整虚拟机各项参数。 命令格式：jinfo[option]pid 参数： -flag：输出指定args参数的值 -flags：不需要args参数，输出所有JVM参数的值 -sysprops：输出系统属性，等同于System.getProperties() jmap（Memory Map for Java）Java内存映像工具用于生成堆转储快照（dump文件） 几种获得dump文件的方式 jmap命令 -XX：+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出现之后自动生成dump文件 -XX：+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成dump文件 在Linux系统下通过Kill-3命令发送进程退出信号也能拿到dump文件 命令格式：jmap[option]vmid 参数： -dump：生成堆转储快照 -finalizerinfo：显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象 -heap：显示Java堆详细信息 -histo：显示堆中对象的统计信息 -permstat：以CLassLoader为统计口径显示永久代内存状态 -F：当-dump没有响应时，强制生成dump快照 jhat（JVM Heap Analysis Tool）与jmap搭配使用，用来分析jmap生成的堆转储快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。 命令格式：jhat [dumpfile] 不推荐使用此命令，有2个原因： 一般不会直接在服务器上分析dump文件，浪费服务器资源。 分析功能简陋，推荐用专业的可视化分析工具，比如VisualVM jstack（Stack Trace for Java）Java堆栈跟踪工具，用于生成虚拟机当前时刻的线程快照。 线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。 命令格式：jstack[option]vmid 参数： -F：当正常输出的请求不被响应时，强制输出线程堆栈 -l：除堆栈外，显示关于锁的附加信息 -m：如果调用本地方法，可显示C/C++的堆栈 在JDK 1.5中，java.lang.Thread类新增了一个getAllStackTraces()方法用于获取虚拟机中所有线程的StackTraceElement对象。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（二）：垃圾收集算法]]></title>
      <url>%2F2018%2F01%2F16%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[判断哪些对象需要被回收 引用计数算法： 给对象中添加一个引用计数器，每当有一个地方引用时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。但是JVM没有使用此方法，因为此方法无法解决2个对象相互循环引用的问题。 可达性分析算法： 这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。 在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。 JDK1.2以后的引用分为4种，引用强度依次逐渐减弱 强引用（Strong Reference） 强引用就是指在程序代码之中普遍存在的，类似Object obj=new Object()这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用（Soft Reference） 软引用是用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK1.2之后，提供了SoftReference类来实现。 弱引用（Weak Reference） 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK1.2之后，提供了WeakReference类来实现。 虚引用（Phantom Reference） 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现。 垃圾收集算法标记-清除算法（Mark-Sweep） 此方法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 主要两个不足：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法（Copying） 此方法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。但是可用内存变成原来的一半，代价较大。 此方法一般用在回收新生代，因为新生代的对象98%都是很快就会被回收，所以不用1:1划分，而是分为一块较大的Eden空间和2块较小的Survivor空间。每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1:1，即新生代中可用内存为90%，只有10%被浪费。标记-整理算法（Mark-Compact） 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法（Generational Collection） 当前商业虚拟机的垃圾收集都采用“分代收集”算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中的异常]]></title>
      <url>%2F2017%2F12%2F05%2FJava%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8%2F</url>
      <content type="text"><![CDATA[Java异常分类所有异常的根类为java.lang.Throwable，Throwable下面又派生了两个子类： Error Exception ErrorError表示应用程序本身无法克服和恢复的一种严重问题，程序只有死的份了。例如，内存溢出和线程死锁等系统问题。 ExceptionException表示程序还能够克服和恢复的问题，其中又分为2类： 系统异常：是软件本身缺陷所导致的问题，也就是软件开发人员考虑不周所导致的问题，软件使用者无法克服和恢复这种问题，但在这种问题下还可以让软件系统继续运行或者让软件死掉。例如，数组下标越界（ArrayIndexOutOfBoundsException），空指针异常（NullPointerException）、类转换异常（ClassCastException）。 编译器不强制用try…catch处理或用throws声明，也称为unchecked异常。 普通异常：是运行环境的变化或异常所导致的问题，是用户能够克服的问题，例如，网络断线，硬盘空间不够，发生这样的异常后，程序不应该死掉。 编译器强制普通异常必须try…catch处理或用throws声明继续抛给上层调用方法处理，也称为checked异常。 常见错误与异常Error： OutOfMemoryError：内存溢出 StackOverflowError：栈溢出 RuntimeException： ClassCastException：类型转换异常 IndexOutOfBoundsException：数组越界 NullPointerException：空指针 ArrayStoreException：数据存储异常，操作数组时类型不一致 BufferOverflowException：缓存区溢出]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK8和JDK9双版本共存]]></title>
      <url>%2F2017%2F09%2F30%2FJDK8%E5%92%8CJDK9%E5%8F%8C%E7%89%88%E6%9C%AC%E5%85%B1%E5%AD%98%2F</url>
      <content type="text"><![CDATA[以前安装JDK，需要手动配置环境变量。JDK8多了自动配置环境变量，所以可以不用手动配置。如果我已经装了JDK8，还想再装一个JDK9，安装完，自动配置的环境变量会指向JDK9版本。 解决方法 删除自动配置的环境变量自动配置的环境变量是一个隐藏目录：C:\ProgramData\Oracle\Java\javapath，删掉这个目录下的3个exe文件，系统就无法匹配到了。 手动配置环境变量自动匹配是匹配不到了，所以我们用老办法，手动配置环境变量即可。这样，我们可以根据环境变量里配置的JDK版本去实现版本切换了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搭建日志分析系统ELK]]></title>
      <url>%2F2017%2F08%2F18%2F%E6%90%AD%E5%BB%BA%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9FELK%2F</url>
      <content type="text"><![CDATA[日志分析组件3件套： E：Elasticsearch是一个搜索引擎，基于Lucene，天然分布式，很容易水平扩展，屏蔽了复杂的分布式概念，对外提供RESTfulAPI。 L：Logstash用于收集日志，写入Elasticsearch。 K：Kibana是一个展示层，基于NodeJS，可以图标形式展示数据，界面简洁。 这3大组件，都可以在 这里 直接下载。 搭建安装步骤： 下载elasticsearch，解压后，运行bin/elasticsearch -d，以守护进程形式启动，打开localhost:9200会返回json信息如下，说明启动成功。 下载Logstash，解压，在/bin/config下创建一个配置文件vi logstash.conf。 1234567891011121314input &#123; tcp &#123; host =&gt; "192.168.1.91" # 要监听的日志来源地址 port =&gt; 4567 mode =&gt; "server" &#125;&#125;output &#123; stdout&#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; ["192.168.1.91:9200"] # elasticsearch中配置的host地址 &#125;&#125; 指定配置文件并后台启动：bin/logstash -f logstash.conf &amp;。 在你的应用程序中配置日志输出到Logstash，比如Logback.xml 引入logstash-logback-encoder：compile group: &#39;net.logstash.logback&#39;, name: &#39;logstash-logback-encoder&#39;, version: &#39;4.11&#39; 配置logback.xml 1234567891011&lt;appender name="stash" class="net.logstash.logback.appender.LogstashTcpSocketAppender"&gt; &lt;destination&gt;192.168.1.91:4567&lt;/destination&gt; &lt;!-- encoder is required --&gt; &lt;encoder class="net.logstash.logback.encoder.LogstashEncoder"/&gt;&lt;/appender&gt;&lt;root level="DEBUG"&gt; &lt;appender-ref ref="stdout"/&gt; &lt;appender-ref ref="fileout"/&gt; &lt;appender-ref ref="stash"/&gt;&lt;/root&gt; 下载Kibana，解压后启动：bin/kibana &amp;，打开localhost:5601即可。 注意事项 在安装Elasticsearch的时候，配置文件中我们把network.host改为0.0.0.0允许远程访问后，启动会报错，请按照 如下操作，放开linux的系统限制。 Elasticsearch入门参考手册]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8学习笔记之新日期API]]></title>
      <url>%2F2017%2F05%2F08%2FJava8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%96%B0%E6%97%A5%E6%9C%9FAPI%2F</url>
      <content type="text"><![CDATA[Java8对日期API做了改进，提供了许多好用的方法和接口。首先，最基本也最重要的3个对象： LocalDate：日期对象 LocalTime：时间对象 LocalDateTime：日期时间对象，是LocalDate和LocalTime的合集 对象的创建以上这3个对象，都各自有3种创建方式。 通过.now()得到当前日期时间对象。 通过.of()直接指定年月日，时分秒。 LocalDate和LocalTime通过解析字符串创建，LocalDateTime可以通过前2个对象创建。 LocalDate对象3种创建方式以及相关方法示例1234567891011121314151617181920212223242526@Testpublic void localDate() &#123; LocalDate date = LocalDate.of(2017, 5, 3); int year = date.getYear();// 2017 Month month = date.getMonth();// MAY int day = date.getDayOfMonth();// 3 DayOfWeek dow = date.getDayOfWeek();// Wednesday int len = date.lengthOfMonth();// 31 boolean leap = date.isLeapYear();// false System.out.println(year + ", " + month + ", " + day + ", " + dow + ", " + len + ", " + leap); LocalDate date2 = LocalDate.now(); int year2 = date2.get(ChronoField.YEAR);// 2017 int month2 = date2.get(ChronoField.MONTH_OF_YEAR);// 5 int day2 = date2.get(ChronoField.DAY_OF_MONTH);// 3 int dow2 = date2.get(ChronoField.DAY_OF_WEEK);// 3 System.out.println(year2 + ", " + month2 + ", " + day2 + ", " + dow2); // 写2017-3-18会报错，DateTimeParseException异常，可以传一个DateTimeFormatter自定义格式 LocalDate date3 = LocalDate.parse("2017-03-18"); int year3 = date3.get(ChronoField.YEAR); int month3 = date3.get(ChronoField.MONTH_OF_YEAR); int day3 = date3.get(ChronoField.DAY_OF_MONTH); int dow3 = date3.get(ChronoField.DAY_OF_WEEK); System.out.println(year3 + ", " + month3 + ", " + day3 + ", " + dow3);&#125; LocalTime对象3种创建方式以及相关方法示例123456789101112131415161718192021@Testpublic void localTime() &#123; LocalTime time = LocalTime.of(11, 06, 23); int hour = time.getHour(); int minute = time.getMinute(); int second = time.getSecond(); System.out.println(hour + ":" + minute + ":" + second); LocalTime time2 = LocalTime.now(); int hour2 = time2.get(ChronoField.HOUR_OF_DAY); int minute2 = time2.get(ChronoField.MINUTE_OF_HOUR); int second2 = time2.get(ChronoField.SECOND_OF_MINUTE); System.out.println(hour2 + ":" + minute2 + ":" + second2); // 写13:5:43会报错，DateTimeParseException异常，可以传一个DateTimeFormatter自定义格式 LocalTime time3 = LocalTime.parse("13:05:43"); int hour3 = time3.get(ChronoField.HOUR_OF_DAY); int minute3 = time3.get(ChronoField.MINUTE_OF_HOUR); int second3 = time3.get(ChronoField.SECOND_OF_MINUTE); System.out.println(hour3 + ":" + minute3 + ":" + second3);&#125; LocalDateTime对象3种创建方式以及相关方法示例12345678910111213141516@Testpublic void localDateTime() &#123; LocalDate date = LocalDate.now(); LocalTime time = LocalTime.now(); // 创建LocalDateTime LocalDateTime dateTime = LocalDateTime.of(2017, 5, 3, 11, 53, 23); LocalDateTime dateTime2 = LocalDateTime.of(date, time); LocalDateTime dateTime3 = date.atTime(11, 53, 23); LocalDateTime dateTime4 = date.atTime(time); LocalDateTime dateTime6 = time.atDate(date); // 转化 LocalDate date2 = dateTime2.toLocalDate(); LocalTime time2 = dateTime2.toLocalTime();&#125; 时间间隔对象 Duration：可以传2个localTime对象，localDateTime对象或者Instant对象 Period：用年，月，日建模，可以传2个localDate对象 12345678910111213 @Test public void between() &#123;// Duration d1 = Duration.between(time1, time2);// Duration d2 = Duration.between(dateTime1, dateTime2);// Duration d3 = Duration.between(instant1, instant2); Period tenDays = Period.between(LocalDate.of(2014, 3, 8), LocalDate.of(2014, 3, 18)); Duration threeMinutes = Duration.ofMinutes(3); Duration threeMinutes2 = Duration.of(3, ChronoUnit.MINUTES); Period tenDays2 = Period.ofDays(10); Period threeWeeks = Period.ofWeeks(3); Period twoYearsSixMonthsOneDay = Period.of(2, 6, 1); &#125; 修改日期时间对象直接使用.with()来修改对应的年月日时分秒属性1234567@Testpublic void editDateTime() &#123; LocalDate date1 = LocalDate.of(2014, 3, 18);// 2014-03-18 LocalDate date2 = date1.withYear(2011);// 2011-03-18 LocalDate date3 = date2.withDayOfMonth(25);// 2011-03-25 LocalDate date4 = date3.with(ChronoField.MONTH_OF_YEAR, 9);// 2011-09-25&#125; 在现有对象上做相对修改1234567@Testpublic void editDateTime() &#123; LocalDate date1 = LocalDate.of(2014, 3, 18);// 2014-03-18 LocalDate date2 = date1.plusWeeks(1);// 2014-03-25 LocalDate date3 = date2.minusYears(3);// 2011-03-25 LocalDate date4 = date3.plus(6, ChronoUnit.MONTHS);// 2011-09-25&#125; 自定义修改日期如果要对日期做一些复杂的修改，那么可以通过TemporalAdjusters接口实现复杂逻辑。123456@Testpublic void adjust() &#123; LocalDate date1 = LocalDate.of(2017, 5, 8);// 2017-05-08 LocalDate date2 = date1.with(TemporalAdjusters.nextOrSame(DayOfWeek.SUNDAY));// 2017-05-14 LocalDate date3 = date2.with(TemporalAdjusters.lastDayOfMonth());// 2017-05-31&#125; jdk为我们实现了一些常用的方法： dayOfWeekInMonth：创建一个新的日期，它的值为同一个月中每一周的第几天 firstDayOfMonth：创建一个新的日期，它的值为当月的第一天 firstDayOfNextMonth：创建一个新的日期，它的值为下月的第一天 firstDayOfNextYear：创建一个新的日期，它的值为明年的第一天 firstDayOfYear：创建一个新的日期，它的值为当年的第一天 firstInMonth：创建一个新的日期，它的值为同一个月中，第一个符合星期几要求的值 lastDayOfMonth：创建一个新的日期，它的值为当月的最后一天 lastDayOfNextMonth：创建一个新的日期，它的值为下月的最后一天 lastDayOfNextYear：创建一个新的日期，它的值为明年的最后一天 lastDayOfYear：创建一个新的日期，它的值为今年的最后一天 lastInMonth：创建一个新的日期，它的值为同一个月中，最后一个符合星期几要求的值 next/previous：创建一个新的日期，并将其值设定为日期调整后或者调整前，第一个符合指定星期几要求的日期 nextOrSame/previousOrSame：创建一个新的日期，并将其值设定为日期调整后或者调整前，第一个符合指定星期几要求的日期，如果该日期已经符合要求，直接返回该对象 自定义格式化输出日期新版本，我们拥有一个线程安全的类：DateTimeFormatter来看代码1234567891011121314151617181920@Testpublic void formatPrint() &#123; LocalDate date = LocalDate.of(2014, 3, 18); String s1 = date.format(DateTimeFormatter.BASIC_ISO_DATE);// 20140318 String s2 = date.format(DateTimeFormatter.ISO_LOCAL_DATE);// 2014-03-18 LocalDate date1 = LocalDate.parse("20140318", DateTimeFormatter.BASIC_ISO_DATE); LocalDate date2 = LocalDate.parse("2014-03-18", DateTimeFormatter.ISO_LOCAL_DATE); // 自定义格式 DateTimeFormatter formatter = DateTimeFormatter.ofPattern("dd/MM/yyyy"); String formattedDate = date.format(formatter); System.out.println(formattedDate);// 18/03/2014 LocalDate date3 = LocalDate.parse(formattedDate, formatter); // 带时区的日期(本地化) DateTimeFormatter italianFormatter = DateTimeFormatter.ofPattern("d. MMMM yyyy", Locale.ITALIAN); String formattedDate2 = date.format(italianFormatter); // 18. marzo 2014 LocalDate date4 = LocalDate.parse(formattedDate2, italianFormatter);&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8学习笔记之Stream API]]></title>
      <url>%2F2017%2F04%2F26%2FJava8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8BStream%20API%2F</url>
      <content type="text"><![CDATA[Stream是Java8引入的一个重度使用lambda表达式的API。Stream可以用流的方式处理数据集合，在Java8之前，我们处理这些集合，是需要迭代器的，比如iterator，这是外部迭代；而Stream是内部迭代，我们不用关心集合内部元素是如何迭代的，计算机会自动帮我们选择最适合的实现方式。 如何创建一个流 最常见的，有一个集合对象List&lt;String&gt; strs = Arrays.asList(&quot;Java 8 &quot;, &quot;Lambdas &quot;, &quot;In &quot;, &quot;Action&quot;);，直接调用strs.stream()就得到一个Stream&lt;String&gt;的流。如果想使用并行流增加性能，请使用strs.parallelStream()，或strs.stream().parallel()。 由值创建：Stream&lt;String&gt; stream = Stream.of(&quot;Java 8 &quot;, &quot;Lambdas &quot;, &quot;In &quot;, &quot;Action&quot;); 由数组创建： 12int[] numbers = &#123;2, 3, 5, 7, 11, 13&#125;;int sum = Arrays.stream(numbers).sum(); 由文件创建： 12345678// 统计文本文件中有多少个不同的单词long uniqueWords = 0;try (Stream&lt;String&gt; lines = Files.lines(Paths.get("data.txt"), Charset.defaultCharset())) &#123; uniqueWords = lines.flatMap(line -&gt; Arrays.stream(line.split(" "))) .distinct() .count();&#125; catch (IOException e) &#123;&#125; 由函数生成流：Stream.iterate()和Stream.generate()可以生产无限流，即元素有无穷多个。一般来说，应该使用limit(n)来对这种流加以限制，以避免产生无穷多个元素。 1234567public void iterator() &#123; Stream.iterate(0, n -&gt; n + 2).limit(10).forEach(System.out::println);&#125;public void generate() &#123; Stream.generate(Math::random).limit(5).forEach(System.out::println);&#125; Stream常用方法 Stream API 支持两种类型的操作：中间操作（如filter或map）和终端操作（如count、findFirst、forEach和reduce）。 我用一个筛选菜单的需求作为示例。 准备工作123456789101112131415161718192021222324252627282930313233343536public class Dish &#123; private final String name; private final boolean vegetarian; private final int calories; private final Type type; public Dish(String name, boolean vegetarian, int calories, Type type) &#123; this.name = name; this.vegetarian = vegetarian; this.calories = calories; this.type = type; &#125; public String getName() &#123; return name; &#125; public boolean isVegetarian() &#123; return vegetarian; &#125; public int getCalories() &#123; return calories; &#125; public Type getType() &#123; return type; &#125; @Override public String toString() &#123; return name; &#125; &#125;public enum Type &#123;MEAT, FISH, OTHER&#125; 123456789101112public List&lt;Dish&gt; init() &#123; return Arrays.asList( new Dish("pork", false, 800, Type.MEAT), new Dish("beef", false, 700, Type.MEAT), new Dish("chicken", false, 400, Type.MEAT), new Dish("french fries", true, 530, Type.OTHER), new Dish("rice", true, 350, Type.OTHER), new Dish("season fruit", true, 120, Type.OTHER), new Dish("pizza", true, 550, Type.OTHER), new Dish("prawns", false, 300, Type.FISH), new Dish("salmon", false, 450, Type.FISH)); &#125; 过滤筛选 谓词：返回boolean的函数 filter()：接受一个谓词，返回符合条件的元素集合 12345678@Testpublic void filter() &#123; List&lt;Dish&gt; menu = init(); List&lt;Dish&gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(Collectors.toList()); Assert.assertEquals(4, vegetarianMenu.size());&#125; distinct()：返回集合中各异的元素集合(去重) 12345@Testpublic void distinct() &#123; List&lt;Integer&gt; numbers = Arrays.asList(5, 1, 2, 1, 3, 3, 2, 4); numbers.stream().distinct().forEach(System.out::println);&#125; limit()：截取流中指定数量的元素，返回一个不超过给定长度的流。如果流是有序的，则最多会返回前n个元素。 123456789``` java @Test public void limit() &#123; List&lt;Dish&gt; menu = init(); menu.stream() .filter(d -&gt; d.getCalories() &gt; 300) .limit(3) .forEach(System.out::println); &#125; skip()：跳过指定数量元素，返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回一个空流。 123456789@Testpublic void skip() &#123; List&lt;Dish&gt; menu = init(); menu.stream() .filter(d -&gt; d.getCalories() &gt; 300) .limit(3) .skip(2) .forEach(System.out::println);&#125; 映射 map()：接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素。 12345@Testpublic void map() &#123; List&lt;Dish&gt; menu = init(); List&lt;String&gt; dishNames = menu.stream().map(m -&gt; m.getName()).collect(Collectors.toList());&#125; flatMap()：一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流，即扁平化为一个流。 12345678910@Testpublic void flatMap() &#123; String[] arrayOfWords = &#123;"Goodbye", "World"&#125;; List&lt;String&gt; words = Arrays.asList(arrayOfWords); words.stream() .map(w -&gt; w.split("")) .flatMap(Arrays::stream) .distinct() .forEach(System.out::println);&#125; 上面例子中，split()得到的是String[] 而不是String，因此各个数组并不是分别映射成一个流，而是映射成流的内容。所有使用map(Arrays::stream)时生成的单个流都被合并起来，变为一个流。 匹配匹配比较简单，返回一个boolean anyMatch()：至少匹配一个 allMatch()：全部匹配 noneMatch()：全部不匹配，和allMatch相反 1234567891011121314151617@Testpublic void anyMatch() &#123; List&lt;Dish&gt; menu = init(); Assert.assertEquals(true, menu.stream().anyMatch(Dish::isVegetarian));&#125;@Testpublic void allMatch() &#123; List&lt;Dish&gt; menu = init(); Assert.assertEquals(true, menu.stream().allMatch(d -&gt; d.getCalories() &lt; 1000));&#125;@Testpublic void noneMatch() &#123; List&lt;Dish&gt; menu = init(); Assert.assertEquals(true, menu.stream().noneMatch(d -&gt; d.getCalories() &gt;= 1000));&#125; 查找查找有2个方法：findFirst()和findAny()，返回一个Optional&lt;T&gt;集合。如果你不关心返回的元素是哪个，请使用findAny()，因为它在使用并行流时限制较少。123456789101112131415161718192021@Testpublic void findFirst() &#123; List&lt;Integer&gt; someNumbers = Arrays.asList(1, 2, 3, 4, 5); Optional&lt;Integer&gt; firstSquareDivisibleByThree = someNumbers.stream() .map(x -&gt; x * x) .filter(x -&gt; x % 3 == 0) .findFirst(); // 9 System.out.println(firstSquareDivisibleByThree.get());&#125;@Testpublic void findAny() &#123; List&lt;Integer&gt; someNumbers = Arrays.asList(1, 2, 3, 4, 5); Optional&lt;Integer&gt; firstSquareDivisibleByThree = someNumbers.stream() .map(x -&gt; x * x) .filter(x -&gt; x % 3 == 0) .findAny(); // 9 System.out.println(firstSquareDivisibleByThree.get());&#125; 归约归约在汇总结合内所有数据的时候使用。比如求 max，min，sum。123456@Testpublic void reduce() &#123; List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5); int sum = numbers.stream().reduce(0, Integer::sum); System.out.println(sum);&#125; 原始类型流特化流在内部迭代的过程中，对基本类型会自动装箱和拆箱。为了避免不需要的装箱拆箱，Java8提供了IntStream、DoubleStream和LongStream 普通流转特化流：mapToInt(), mapToLong(), mapToDouble() 特化流转普通流：boxed() 1234567public void boxedStream() &#123; List&lt;Dish&gt; menu = init(); // 特化 IntStream intStream = menu.stream().mapToInt(Dish::getCalories); // 转回普通Stream Stream&lt;Integer&gt; stream = intStream.boxed();&#125; Java 8引入了两个可以用于IntStream和LongStream的静态方法，用于生成给定范围的数字流： range(min, max)：随机生成的数字不包含max，即(min, max) rangeClosed(min, max)：随机生成的数字包含max，即(min, max]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8学习笔记之Lambda表达式]]></title>
      <url>%2F2017%2F04%2F19%2FJava8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8BLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[使用Lambda表达式，我们可以很简洁地传递代码（通常是匿名函数）。 结构Lambda表达式主要分为三部分：参数列表，箭头，Lambda 主体 语法 (parameters) -&gt; expression (parameters) -&gt; { statements; } 如果表达式只有一行，用第一种，多行用第二种。 Java8中，标注了@FunctionalInterface，表明这个接口将是一个函数式接口，它里面只能有一个抽象方法。 常用的函数式接口JDK已经为我们提供了很多常用的函数式接口： Predicate：java.util.function.Predicate&lt;T&gt;接口定义了一个名叫test的抽象方法，它接受泛型T对象，并返回一个boolean。在需要表示一个涉及类型T的布尔表达式时可以使用。 Consumer：java.util.function.Consumer&lt;T&gt;定义了一个名叫accept的抽象方法，它接受泛型T的对象，没有返回（void）。如果需要访问类型T的对象，并对其执行某些操作，就可以使用这个接口。 Supplier：java.util.function.Supplier&lt;T&gt;不接受对象，返回一个泛型对象T。在需要new一个对象实例时可以使用。 Function：java.util.function.Function&lt;T, R&gt;接口定义了一个叫作apply的方法，它接受一个泛型T的对象，并返回一个泛型R的对象。如果需要定义一个Lambda，将输入对象的信息映射到输出，就可以使用这个接口。 原始类型特化我们知道，泛型只能绑定到引用类型的对象。因此，在使用泛型绑定基本类型的时候，Java会为我们自动装箱和拆箱，但这是会消耗性能的。如果输入和输出都是基本类型时，Java8为我们提供了新的函数式接口，以避免自动装箱拆箱。 简单列举一部分： Predicate：IntPredicate, LongPredicate, DoublePredicate Consumer：IntConsumer,LongConsumer, DoubleConsumer Supplier：BooleanSupplier, IntSupplier, LongSupplier, DoubleSupplier Function：IntFunction&lt;R&gt;,LongToDoubleFunction,ToLongFunction&lt;T&gt; 从命名可以轻易看出从什么类型转成什么类型，可以在java.util.function包下查看所有接口。 使用局部变量在使用lambda时，主体代码块内允许使用的外部变量。但是，不允许改变外部变量。这些变量应该声明为final或者事实上是final的（即之后代码中不会改变） 方法引用方法引用主要有三类： 指向静态方法的方法引用 Lambda: (args) -&gt; ClassName.staticMethod(args) 方法引用：ClassName :: staticMethod 指向任意类型实例方法的方法引用 Lambda: (arg0, rest) -&gt; arg0.instanceMethod(rest) 方法引用：ClassName :: instanceMethod(arg0 是 ClassName 类型的) 指向现有对象的实例方法的方法引用 Lambda: (args) -&gt; expr.instanceMethod(args) 方法引用：expr :: intanceMethod 除此之外，还有构造函数引用：ClassName :: new比如用Map来将构造函数映射到字符串值：12345678910static Map&lt;String, Function&lt;Integer, Fruit&gt;&gt; map = new HashMap&lt;&gt;();static &#123; map.put("apple", Apple::new); map.put("orange", Orange::new); // etc...&#125;public static Fruit giveMeFruit(String fruit, Integer weight) &#123; return map.get(fruit.toLowerCase()).apply(weight);&#125; 复合 Lambda 表达式Comparator、Predicate和Function等函数式接口都有几个可以用来结Lambda表达式的默认方法。 比较器复合 普通排序comparing() 1Comparator&lt;Apple&gt; c = Comparator.comparing(Apple::getWeight); 逆序reversed() 1inventory.sort(comparing(Apple::getWeight).reversed()); 比较器链thenComparing() 12inventory.sort(comparing(Apple::getWeight).reversed() .thenComparing(Apple::getCountry)); 谓词复合3个方法增强已有的Predicate接口： and：与 or：或 negate：非 请注意，and和or方法是按照在表达式链中的位置，从左向右确定优先级的。因此，a.or(b).and(c)可以看作(a || b) &amp;&amp; c。 函数复合Function接口有andThen和compose两个默认方法，它们都会返回Function的一个实例。 举个例子：有2个函数，一个加1，一个乘212Function&lt;Integer, Integer&gt; f = x -&gt; x + 1; // f(x)=x+1Function&lt;Integer, Integer&gt; g = x -&gt; x * 2; // g(x)=2x andThen() 12Function&lt;Integer, Integer&gt; h = f.andThen(g); // g(f(x))int result = h.apply(1); // 4 compose() 12Function&lt;Integer, Integer&gt; h = f.compose(g); // f(g(x))int result = h.apply(1); // 3]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8学习笔记之行为参数化]]></title>
      <url>%2F2017%2F04%2F19%2FJava8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E8%A1%8C%E4%B8%BA%E5%8F%82%E6%95%B0%E5%8C%96%2F</url>
      <content type="text"><![CDATA[用一个例子说明行为参数化带来的变化 - 从苹果仓库中筛选苹果 版本1从一个苹果集合中选出绿的苹果123456789public static List&lt;Apple&gt; filterGreenApples(List&lt;Apple&gt; inventory) &#123; List&lt;Apple&gt; result = new ArrayList&lt;Apple&gt;(); for (Apple apple : inventory) &#123; if ("green".equals(apple.getColor()) &#123; result.add(apple); &#125; &#125; return result; &#125; 版本2这时，如果需求变了，要从集合中选出红苹果，我们会这样123456789public static List&lt;Apple&gt; filterApplesByColor(List&lt;Apple&gt; inventory, String color) &#123; List&lt;Apple&gt; result = new ArrayList&lt;Apple&gt;(); for (Apple apple : inventory) &#123; if (apple.getColor().equals(color)) &#123; result.add(apple); &#125; &#125; return result; &#125; 然后传入颜色参数来筛选1List&lt;Apple&gt; apples = filterApplesByColor(inventory, "red"); 版本3但是，如果现在要选出重量超过150g的苹果呢？在方法参数列表中多加一个weight么？你会发现我们所有的代码，只有if判断中的条件发生了变化，这违反了DRY原则(Don’t Repeat Yourself)。 所以，我们把整个具体行为作为参数来传递，这样，方法体本身的代码就可以复用了。12345678910111213141516// 定义一个接口public interface ApplePredicate &#123; boolean test(Apple apple);&#125;public class AppleHeavyWeightPredicate implements ApplePredicate &#123; public boolean test(Apple apple) &#123; return apple.getWeight() &gt; 150; &#125;&#125;public class AppleGreenColorPredicate implements ApplePredicate &#123; public boolean test(Apple apple) &#123; return "green".equals(apple.getColor()); &#125;&#125; 123456789public static List&lt;Apple&gt; filterApples(List&lt;Apple&gt; inventory, ApplePredicate p) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); for (Apple apple : inventory) &#123; if (p.test(apple)) &#123; result.add(apple); &#125; &#125; return result;&#125; 现在，我们可以很灵活的调用了1List&lt;Apple&gt; redAndHeavyApples = filterApples(inventory, new AppleHeavyWeightPredicate()); 版本4其实，接口的具体实现，我们只会用到一次。所以，我们可以改成匿名类：12345List&lt;Apple&gt; redApples = filterApples(inventory, new ApplePredicate() &#123; public boolean test(Apple apple) &#123; return "red".equals(apple.getColor()); &#125; &#125;); 现在，代码已经变得非常简洁和灵活了。 版本5从Java8开始，我们可以利用Lambda表达式，进一步改进代码：1List&lt;Apple&gt; result = filterApples(inventory, (Apple apple) -&gt; "red".equals(apple.getColor())); 现在，调用方法，我们只要一行代码，而且代码的可读性非常好。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HTML转图片利器：wkhtmltox]]></title>
      <url>%2F2017%2F04%2F01%2FHTML%E8%BD%AC%E5%9B%BE%E7%89%87%E5%88%A9%E5%99%A8%EF%BC%9Awkhtmltox%2F</url>
      <content type="text"><![CDATA[关于wkhtmltox，是一个可以把HTML转换为图片和pdf的工具。 不多介绍了，详见官网 https://wkhtmltopdf.org/ 安装步骤 下载下来是tar.xz文件，首先解压：tar -vxf wkhtmltox-0.12.4_linux-generic-amd64.tar.xz 解压得到一个目录wkhtmltox，把wkhtmltoimage和wkhtmltopdf复制到/usr/bin目录，更改所有者，并增加可执行属性 123456sudo cp wkhtmltox/bin/wkhtmltopdf /usr/bin/sudo cp wkhtmltox/bin/wkhtmltoimage /usr/bin/sudo chown root:root /usr/bin/wkhtmltopdfsudo chown root:root /usr/bin/wkhtmltoimagesudo chmod +x /usr/bin/wkhtmltopdfsudo chmod +x /usr/bin/wkhtmltoimage 注意事项 有时候为了让程序可以执行这个命令，可能需要配置环境变量 编辑配置文件 vi .bashrc 添加环境变量 export PATH=$PATH:/opt/wkhtmltox/bin 让修改生效 source .bashrc让修改生效 如果网页上的中文，转成图片后变成乱码方块，请安装相关字体 :) 关于使用执行wkhtmltoimage www.bing.com bing.png，就会在当前目录下生成了一张png图片。 这个命令还可以增加一些参数，比如常用的设置宽高，图片质量等参数执行wkhtmltoimage --crop-w 410 --width 410 --quality 50 www.bing.com bing2.png看看 说明: --crop-w 410：截图宽度410px --width 410：浏览器模拟宽度410px --quality 50：图片质量(这个值越大，图片质量越高，当然文件也会比较大) 还有更多参数用法，请 wkhtmltoimage -h查看。HTML转pdf同理，wkhtmltopdf -h。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot中使用Redis实现缓存]]></title>
      <url>%2F2017%2F03%2F30%2FSpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E7%BC%93%E5%AD%98%2F</url>
      <content type="text"><![CDATA[Spring Data Redis为我们封装了Redis客户端的各种操作，简化使用。 当Redis当做数据库或者消息队列来操作时，我们一般使用RedisTemplate来操作 当Redis作为缓存使用时，我们可以将它作为Spring Cache的实现，直接通过注解使用 关于RedisTemplate的使用可参考：http://blog.didispace.com/springbootredis/ 下面总结使用Redis作为缓存引入依赖SpringBoot从1.4版本开始，spring-boot-starter-redis依赖改名了。12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置文件1234567891011spring: redis: host: 127.0.0.1 port: 6379 timeout: 0 database: 0 pool: max-active: 8 max-wait: -1 max-idle: 8 min-idle: 0 这样，SpringBoot将会自动配置redis，注入相关bean，我们就可以使用@CacheConfig，@Cacheable，@CachePut，@CacheEvict了。 使用Cache注解时的问题缓存对象集合中，缓存是以key-value形式保存的。当不指定缓存的key时，SpringBoot会使用SimpleKeyGenerator生成key。1234567891011121314151617181920212223public class SimpleKeyGenerator implements KeyGenerator &#123; @Override public Object generate(Object target, Method method, Object... params) &#123; return generateKey(params); &#125; /** * Generate a key based on the specified parameters. */ public static Object generateKey(Object... params) &#123; if (params.length == 0) &#123; return SimpleKey.EMPTY; &#125; if (params.length == 1) &#123; Object param = params[0]; if (param != null &amp;&amp; !param.getClass().isArray()) &#123; return param; &#125; &#125; return new SimpleKey(params); &#125;&#125; 123456public SimpleKey(Object... elements) &#123; Assert.notNull(elements, "Elements must not be null"); this.params = new Object[elements.length]; System.arraycopy(elements, 0, this.params, 0, elements.length); this.hashCode = Arrays.deepHashCode(this.params);&#125; 查看源码可以发现，它是使用方法参数组合生成的一个key。此时有一个问题：如果2个方法，参数是一样的，但执行逻辑不同，那么将会导致执行第二个方法时命中第一个方法的缓存。解决办法是在@Cacheable注解参数中指定key，或者自己实现一个KeyGenerator，在注解中指定KeyGenerator。但是如果这样的情况很多，每一个都要指定key、KeyGenerator很麻烦。 Spring同样提供了方案：继承CachingConfigurerSupport并重写keyGenerator() 下面贴出代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@EnableCaching@Configurationpublic class RedisCacheConfig extends CachingConfigurerSupport &#123; @Autowired private JedisConnectionFactory jedisConnectionFactory; @Bean public RedisTemplate redisTemplate() &#123; StringRedisTemplate redisTemplate = new StringRedisTemplate(jedisConnectionFactory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125; @Bean public CacheManager cacheManager() &#123; String[] cacheNames = &#123;"app_default", "users", "blogs", "goods", "configs", "info"&#125;; RedisCacheManager redisCacheManager = new RedisCacheManager(redisTemplate(), Arrays.asList(cacheNames)); redisCacheManager.setDefaultExpiration(86400); return redisCacheManager; &#125; @Bean public Cache cache() &#123; return cacheManager().getCache("app_default"); &#125; @Bean @Override public KeyGenerator keyGenerator() &#123; return (target, method, objects) -&gt; &#123; StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append("::" + method.getName() + ":"); for (Object obj : objects) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125;; &#125;&#125; 此时，缓存的key是包名+方法名+参数列表，这样就很难会冲突了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[手动安装redis-3.2.8的详细步骤]]></title>
      <url>%2F2017%2F03%2F30%2F%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85redis-3.2.8%E7%9A%84%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%2F</url>
      <content type="text"><![CDATA[CentOS6.7使用yum安装有时候没有比较新的版本，所以手动安装，下面记录一下步骤。 下载最新版本以3.2.8为例，附上地址：redis-3.2.8.tar.gz 解压，编译，安装redis 解压：tar -zxvf redis-3.2.8.tar.gz 进入目录：cd redis-3.2.8 编译：make &amp;&amp; make install 创建相关目录： 1234mkdir -p /opt/redis-3.2.8/binmkdir -p /opt/redis-3.2.8/logmkdir -p /opt/redis-3.2.8/pidmkdir -p /opt/redis-3.2.8/db 将编译后的可执行文件复制到自己的安装目录：ln -s /usr/local/bin/redis-* /opt/redis-3.2.8/bin 复制配置文件到安装目录：cp redis.conf /opt/redis-3.2.8/ 配置redis 编辑redis.conf：cd /opt/redis-3.2.8，vi redis.conf redis默认只允许本机连接，所以注释掉这行配置就可以远程访问：\# bind 127.0.0.1 redis3.0版本增加了保护模式，需要我们设置密码，如果不想设置密码，就关闭保护模式：protected-mode no 设置redis以守护线程方式启动：daemonize yes 配置pid，log，db文件的保存地址：123pidfile /opt/redis-3.2.8/pid/redis.pidlogfile /opt/redis-3.2.8/log/redis.logdir /opt/redis-3.2.8/db 其他配置就默认即可，有需要再自行修改 编写redis启动脚本：vi /etc/init.d/redis 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/sh## Simple Redis init.d script conceived to work on Linux systems# as it does use of the /proc filesystem.PATH=/opt/redis-3.2.8/bin:/sbin:/usr/bin:/binREDISPORT=6379EXEC=/opt/redis-3.2.8/bin/redis-serverCLIEXEC=/opt/redis-3.2.8/bin/redis-cliPIDFILE=/opt/redis-3.2.8/pid/redis.pidCONF="/opt/redis-3.2.8/redis.conf"case "$1" in start) if [ -f $PIDFILE ] then echo "$PIDFILE exists, process is already running or crashed" else echo "Starting Redis server..." $EXEC $CONF fi ;; stop) if [ ! -f $PIDFILE ] then echo "$PIDFILE does not exist, process is not running" else PID=$(cat $PIDFILE) echo "Stopping ..." $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/$&#123;PID&#125; ] do echo "Waiting for Redis to shutdown ..." sleep 1 done echo "Redis stopped" fi ;; *) echo "Please use start or stop as first argument" ;;esac 设置服务权限：chmod a+x /etc/init.d/redis 相关使用 启动：service redis start 关闭：service redis stop 查看：ps -ef | grep redis，netstat -anptu | grep 6379]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[谈谈Java中的代理]]></title>
      <url>%2F2017%2F02%2F17%2F%E8%B0%88%E8%B0%88Java%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%90%86%2F</url>
      <content type="text"><![CDATA[代理是Java常用的设计模式，代理类通过调用被代理类的相关方法，实现对相关方法增强。比如加入事务、日志、报警发邮件等操作。 静态代理静态代理，就是由程序员手动编写代理类或者用工具生成代理类的代码，再进行编译生成class文件，实现代理。比如简单工厂模式。 用法： 代理类和目标类都实现相同接口。 代理类持有目标类的引用。 缺点：静态代理要为每个目标类创建一个代理类，当需要代理的对象太多，那么代理类也变得很多。代理类违背了可重复代理只写一次的原则。 动态代理为了解决静态代理的缺点，于是引入了动态代理。它有一个好处，那就是不用写很多代理类，生成的代理类数量是固定的。一般动态代理分为2种： JDK动态代理JDK动态代理是JDK自带的，不依赖第三方框架。它的实现原理，就是利用Java的反射机制，创建一个实现接口的代理类。 用法： 被代理对象必须实现接口。 代理对象由代理工厂自动生成。 下面贴个例子 接口类：123public interface Subject &#123; public void doSomething(); &#125; 实现类：12345public class RealSubject implements Subject &#123; public void doSomething() &#123; System.out.println("do 了 some thing ..."); &#125; &#125; 代理工厂：12345678910111213141516171819202122232425import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class ProxyHandler implements InvocationHandler &#123; private Object target; //绑定委托对象，并返回代理类 public Object bind(Object target) &#123; this.target = target; //绑定该类实现的所有接口，取得代理类 return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy , Method method , Object[] args)throws Throwable &#123; Object result = null; //这里就可以进行所谓的AOP编程了 //在调用具体函数方法前，执行功能处理 result = method.invoke(target, args); //在调用具体函数方法后，执行功能处理 return result; &#125;&#125; 测试类：12345678public class TestProxy &#123; public static void main(String args[]) &#123; ProxyHandler proxy = new ProxyHandler(); //绑定该类实现的所有接口 Subject sub = (Subject) proxy.bind(new RealSubject()); sub.doSomething(); &#125;&#125; CGLIB代理使用CGLIB代理需要引入CGLIB库，它使用字节码技术实现代理。1234567891011121314151617181920212223242526272829303132import java.lang.reflect.Method;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy; public class CGLibProxy implements MethodInterceptor &#123; private Object targetObject;// CGLib需要代理的目标对象 public Object createProxyObject(Object obj) &#123; this.targetObject = obj; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(obj.getClass()); enhancer.setCallback(this); Object proxyObj = enhancer.create(); return proxyObj;// 返回代理对象 &#125; public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object obj = null; if ("addUser".equals(method.getName())) &#123;// 过滤方法 checkPopedom();// 检查权限 &#125; obj = method.invoke(targetObject, args); return obj; &#125; private void checkPopedom() &#123; System.out.println("检查权限 checkPopedom()!"); &#125; &#125; 1234567public class Test &#123; public static void main(String[] args) &#123; Subject sub = (Subject) new CGLibProxy().createProxyObject(new RealSubject()); sub.doSomething();&#125; 2种动态代理的区别JDK动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。而CGLIB动态代理是利用asm开源包，加载代理对象类的class文件，修改其字节码生成子类来处理。 在 Spring 中， 如果目标对象实现了接口，默认情况下会采用JDK动态代理实现AOP 如果目标对象实现了接口，可以强制使用CGLIB实现AOP 如果目标对象没有实现了接口，必须采用CGLIB库，Spring会自动在JDK动态代理和CGLIB之间转换 如何强制使用CGLIB实现AOP？ 添加CGLIB依赖 在Spring配置文件中加入&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt; 如果是SpringBoot，在配置文件设置spring.aop.proxy-target-class=true JDK动态代理和CGLIB字节码生成的区别？ JDK动态代理只能对实现了接口的类生成代理，而不能针对未实现接口的类 CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法 因为是继承，所以该类或方法最好不要声明成final]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解JVM（一）：JVM内存结构]]></title>
      <url>%2F2017%2F02%2F16%2F%E7%90%86%E8%A7%A3JVM%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AJVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[在JVM中，内存主要被分为5类 堆Heap 虚拟机内存管理中最大的一块内存空间。 存放关键字new创建的对象实例和数组。 堆内存被所有线程共享。 这块内存区由JVM（Java虚拟机）自己管理。当使用new创建对象时，不必指定分配空间的大小，JVM会动态自动分配一块区域；在程序执行过程中，没有指向此对象的引用时，此对象就被标记为可被回收状态，将由GC（垃圾回收器）在一个不确定的时间自动回收，释放所占的内存空间。 从内存回收的角度看，垃圾收集器大都基于分代收集算法，所以堆一般分为新生代和老年代，更细致可划分为：Eden空间，From Survivor空间，To Survivor空间。 虚拟机栈VM Stack 存放8种基本类型的数据和对象引用（不是对象）。 每个线程有自己的单独的栈。 先进后出，后进先出。 因为主要存放基本类型数据变量，所以分配空间比堆快。当超出变量的作用域，将由编译器立即释放空间。 本地方法栈Native Method Stack 与虚拟机栈类似，虚拟机栈为虚拟机调用Java方法服务，本地方法栈为虚拟机调用Native方法服务。 在HotSpot虚拟机实现中，虚拟机栈和本地方法栈被合并为一个区域。 程序计数器 Program Counter Register一块较小的内存空间，可看作是当前线程所执行的字节码的 行号指示器。 通过改变计数器的值来选取下一条需要执行的字节码指令。（分支、循环、跳转、异常处理、线程恢复等）基础功能都依赖与其完成。 特点： 线程私有：因为 Java 虚拟机的多线程是通过 线程轮流切换 并 分配处理器执行时间 来实现的，在某一时刻，只会执行一条线程。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器。 无内存溢出：如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在 执行的虚拟机字节码指令的地址；如果正在执行的是 Native 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机程序规范中没有规定任何 OutOfMemoryError 情况的区域。 方法区Method Area 跟堆一样，被所有的线程共享。 是一个内存逻辑区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 运行时常量池Runtime Constant Pool 方法区的一部分。 Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 直接内存Direct Memory直接内存不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现。 在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC统一异常处理总结]]></title>
      <url>%2F2017%2F02%2F15%2FSpringMVC%E7%BB%9F%E4%B8%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[在一个Spring MVC项目中，使用统一异常处理，可以使维护代码变得容易。下面总结一下常用的3种方法。 实现HandlerExceptionResolver接口实现HandlerExceptionResolver接口，实现resolveException()方法，根据传入的异常类型做出处理。 继承AbstractHandlerExceptionResolver类继承AbstractHandlerExceptionResolver类，和第一种方式类似，因为AbstractHandlerExceptionResolver实现了HandlerExceptionResolver接口。所以，我们继承之后也是重写resolveException()方法，再处理各种异常。 使用注解@ControllerAdvice处理推荐使用这种方法，比较直观。下面上代码： 首先是自定义异常类1234567891011121314151617181920212223public class ResourceDoesNotExistException extends RuntimeException &#123; private static final long serialVersionUID = 7833283455112352655L; public ResourceDoesNotExistException() &#123; super(); &#125; public ResourceDoesNotExistException(String message) &#123; super(message); &#125; public ResourceDoesNotExistException(String message, Throwable cause) &#123; super(message, cause); &#125; public ResourceDoesNotExistException(Throwable cause) &#123; super(cause); &#125; protected ResourceDoesNotExistException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) &#123; super(message, cause, enableSuppression, writableStackTrace); &#125;&#125; 然后是全局异常统一处理类：123456789101112131415@ControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(value = OtherException.class) public ModelAndView defaultErrorHandler(HttpServletRequest req, Exception ex) &#123; // 其他异常处理逻辑... &#125; @ExceptionHandler(value = ResourceDoesNotExistException.class) public ModelAndView notFoundErrorHandler(HttpServletRequest req, ResourceDoesNotExistException ex) &#123; ModelAndView mav = new ModelAndView(); mav.setViewName("404"); return mav; &#125;&#125; 添加@ControllerAdvice注解的类是集中处理异常的地方，可以同时存在多个这样的类，用来做更细粒度的划分。在这个类中，我们可以对每一种异常编写一种处理逻辑，在方法上使用@ExceptionHandler注解修饰，传入指定的异常类型即可。如果是RESTful风格，不返回视图，也可使用@RestControllerAdvice。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring Task定时任务的配置和使用]]></title>
      <url>%2F2017%2F02%2F15%2FSpring%20Task%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[记录下Spring自带的定时任务用法。 spring中使用定时任务基于xml配置文件使用定时任务首先配置spring开启定时任务123456789101112131415161718192021222324252627&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:task="http://www.springframework.org/schema/task" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.0.xsd"&gt; &lt;task:annotation-driven /&gt; &lt;!-- 定时器开关--&gt; &lt;bean id="myTask" class="com.spring.task.MyTask"&gt;&lt;/bean&gt; &lt;task:scheduled-tasks&gt; &lt;!-- 这里表示的是每隔五秒执行一次 --&gt; &lt;task:scheduled ref="myTask" method="show" cron="*/5 * * * * ?" /&gt; &lt;task:scheduled ref="myTask" method="print" cron="*/10 * * * * ?"/&gt; &lt;/task:scheduled-tasks&gt; &lt;!-- 自动扫描的包名 --&gt; &lt;context:component-scan base-package="com.spring.task" /&gt;&lt;/beans&gt; 定义自己的任务执行逻辑 123456789101112131415package com.spring.task; /** * 定义任务 */ public class MyTask &#123; public void show() &#123; System.out.println("show method 1"); &#125; public void print() &#123; System.out.println("print method 1"); &#125; &#125; 基于注解使用定时任务1234567891011121314151617181920212223242526package com.spring.task; import org.springframework.scheduling.annotation.Scheduled; import org.springframework.stereotype.Component; /** * 基于注解的定时器 */@Componentpublic class MyTask2 &#123; /** * 定时计算。每天凌晨 01:00 执行一次 */ @Scheduled(cron = "0 0 1 * * *") public void show() &#123; System.out.println("show method 2"); &#125; /** * 启动时执行一次，之后每隔2秒执行一次 */ @Scheduled(fixedRate = 1000*2) public void print() &#123; System.out.println("print method 2"); &#125;&#125; 这样，当项目启动，定时任务就会按照规则按时执行了。 Spring Boot中使用定时任务Spring Boot中使用更加方便。 引入springboot starter包1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 在程序入口启动类添加@EnableScheduling，开启定时任务功能12345678@SpringBootApplication@EnableSchedulingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 定义定时任务逻辑12345678910@Componentpublic class MyTask3 &#123; private int count=0; @Scheduled(cron="*/6 * * * * ?") private void process() &#123; System.out.println("this is scheduler task runing "+(count++)); &#125;&#125; 任务执行规则说明注解参数说明先来看看@Scheduled注解的源码12345678910111213141516171819202122@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(Schedules.class)public @interface Scheduled &#123; String cron() default ""; String zone() default ""; long fixedDelay() default -1; String fixedDelayString() default ""; long fixedRate() default -1; String fixedRateString() default ""; long initialDelay() default -1; String initialDelayString() default "";&#125; 可以看出，注解中可以传8种参数： cron：指定cron表达式 zone：默认使用服务器默认时区。可以设置为java.util.TimeZone中的zoneId fixedDelay：从上一个任务完成开始到下一个任务开始的间隔，单位毫秒 fixedDelayString：同上，时间值是String类型 fixedRate：从上一个任务开始到下一个任务开始的间隔，单位毫秒 fixedRateString：同上，时间值是String类型 initialDelay：任务首次执行延迟的时间，单位毫秒 initialDelayString：同上，时间值是String类型 cron表达式的用法Cron表达式是一个字符串，字符串以5或6个空格隔开，分为6或7个域，每一个域代表一个含义，Cron有如下两种语法格式： Seconds Minutes Hours DayofMonth Month DayofWeek Year Seconds Minutes Hours DayofMonth Month DayofWeek 每一个域可出现的字符如下： Seconds: 可出现”, - * /“四个字符，有效范围为0-59的整数 Minutes: 可出现”, - * /“四个字符，有效范围为0-59的整数 Hours: 可出现”, - * /“四个字符，有效范围为0-23的整数 DayofMonth: 可出现”, - * / ? L W C”八个字符，有效范围为0-31的整数 Month: 可出现”, - * /“四个字符，有效范围为1-12的整数或JAN-DEC DayofWeek: 可出现”, - * / ? L C #”四个字符，有效范围为1-7的整数或SUN-SAT两个范围。1表示星期天，2表示星期一， 依次类推 Year: 可出现”, - * /“四个字符，有效范围为1970-2099年 每一个域都使用数字，但还可以出现如下特殊字符，它们的含义是： *：表示匹配该域的任意值，假如在Minutes域使用*, 即表示每分钟都会触发事件。 ?：只能用在DayofMonth和DayofWeek两个域。它也匹配域的任意值，但实际不会。因为DayofMonth和 DayofWeek会相互影响。例如想在每月的20日触发调度，不管20日到底是星期几，则只能使用如下写法： 13 13 15 20 ?, 其中最后一位只能用？，而不能使用，如果使用*表示不管星期几都会触发，实际上并不是这样。 -：表示范围，例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次。 /：表示起始时间开始触发，然后每隔固定时间触发一次，例如在Minutes域使用5/20,则意味着5分钟触发一次，而25，45等分别触发一次。 ,：表示列出枚举值值。例如：在Minutes域使用5,20，则意味着在5和20分每分钟触发一次。 L：表示最后，只能出现在DayofWeek和DayofMonth域，如果在DayofWeek域使用5L,意味着在最后的一个星期四触发。 W：表示有效工作日(周一到周五),只能出现在DayofMonth域，系统将在离指定日期的最近的有效工作日触发事件。例如：在 DayofMonth使用5W，如果5日是星期六，则将在最近的工作日：星期五，即4日触发。如果5日是星期天，则在6日(周一)触发；如果5日在星期一 到星期五中的一天，则就在5日触发。另外一点，W的最近寻找不会跨过月份。 LW：这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。 #：用于确定每个月第几个星期几，只能出现在DayofMonth域。例如在4#2，表示某月的第二个星期三。 参考 cron表达式例子]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用SpringBoot Actuator监控应用]]></title>
      <url>%2F2017%2F02%2F13%2F%E4%BD%BF%E7%94%A8SpringBoot%20Actuator%E7%9B%91%E6%8E%A7%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[Actuator是Spring Boot提供的对应用系统的自省和监控的集成功能，可以对应用系统进行配置查看、相关功能统计等。 使用Actuator引入依赖即可 Maven： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; Gradle： 1compile(&apos;org.springframework.boot:spring-boot-starter-actuator&apos;) Endpoints列举一些主要的endpoints 配置文件属性介绍地址和端口的配置 management.port：指定访问这些监控方法的端口，与逻辑接口端口分离。如果不想将这些暴露在http中，可以设置 management.port = -1 management.address：指定地址，比如只能通过本机监控，可以设置 management.address = 127.0.0.1 敏感信息访问限制根据上面表格，鉴权为false的，表示不敏感，可以随意访问，否则就是做了一些保护，不能随意访问。 endpoints.mappings.sensitive=false 这样需要对每一个都设置，比较麻烦。敏感方法默认是需要用户拥有ACTUATOR角色，因此，也可以设置关闭安全限制： management.security.enabled=false 或者配合Spring Security做细粒度控制。 自定义系统信息可以通过访问/info获取信息，需要在配置文件设置1234567891011info: aaa: name: xxx email: xxx@qq.com bbb: age: 25 hobbies: running build: artifact: "@project.artifactId@" name: "@project.name@" version: "@project.version@" 此时访问localhost:8080/info返回一下信息 如果使用maven，可以访问pom.xml文件的信息，用法如下: // 获取pom.xml中project节点下artifactId属性artifact: “@project.artifactId@” 其他/shutdown这个需要post方式，通过请求来关闭应用。这个操作比较敏感，要想真正生效，需要以下配置: endpoints.shutdown.enabled: true 我们可以通过实现HealthIndicator接口，编写自己的/health方法逻辑。也可以增加自定义监控方法。 查看详细介绍，请移步 官方文档]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在SpringBoot中使用Logback管理日志]]></title>
      <url>%2F2017%2F02%2F11%2F%E5%9C%A8SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Logback%E7%AE%A1%E7%90%86%E6%97%A5%E5%BF%97%2F</url>
      <content type="text"><![CDATA[SpringBoot的默认日志配置SpringBoot开箱即用，默认帮你配置了日志框架，使用 Commons Logging ，但是默认配置也提供了对常用日志的支持，如： Java Util Logging ， Log4J , Log4J2 和 Logback。每种Logger都可以通过配置使用控制台或者文件输出日志内容。 控制台输出关于log日志，首先说说的5个日志级别 LEVEL：从高到低分别是ERROR、WARN、INFO、DEBUG、TRACE低级别的会输出高级别信息，高级别不会输出低级别信息。例如：等级设为ERROR的话，WARN、INFO、DEBUG的信息是不会输出的。在SpringBoot中默认配置了ERROR 、WARN和INFO级别的日志输出到控制台。Logback中没有FATAL级别，它会被当作ERROR级别来处理。 我们可以通过两种方式切换至 DEBUG 级别： 在运行命令后加入 –debug 标志，如： $ java -jar myapp.jar –debug 在 application.properties 中配置 debug=true ，该属性置为true的时候，核心Logger（包含嵌入式容器、hibernate、spring）会输出更多内容，但是你自己应用的日志并不会输出为DEBUG级别。 多彩输出SpringBoot从1.4.0版本开始支持彩色日志输出了。如果你的终端支持ANSI，设置彩色输出会让日志更具可读性。通过在 application.properties 中设置 spring.output.ansi.enabled 参数来支持。 NEVER：禁用ANSI-colored输出（默认项） DETECT：会检查终端是否支持ANSI，是的话就采用彩色输出（推荐项） ALWAYS：总是使用ANSI-colored格式输出，若终端不支持的时候，会有很多干扰信息，不推荐使用 文件输出SpringBoot默认配置只会输出到控制台，并不会记录到文件中，但是我们通常生产环境使用时都需要以文件方式记录。 若要增加文件输出，需要在 application.properties 中配置 logging.file 或 logging.path 属性。 logging.file:设置文件，可以是绝对路径，也可以是相对路径。如： logging.file=my.log logging.path:设置目录，会在该目录下创建spring.log文件，并写入日志内容，如： logging.path=/var/log 日志文件会在10Mb大小的时候被截断，产生新的日志文件，默认级别为：ERROR、WARN、INFO 级别控制在SpringBoot中只需要在 application.properties 中进行配置完成日志记录的级别控制。 配置格式： logging.level.*=LEVEL logging.level ：日志级别控制前缀， * 为包名或Logger名 LEVEL ：选项TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF 举例： logging.level.com.controller=DEBUG ： com.controller包下所有class以DEBUG级别输出 logging.level.root=WARN ：root日志以WARN级别输出 自定义日志配置如果不想使用默认配置，只要加入自己的日志配置文件就行了。由于日志服务一般都在ApplicationContext创建前就初始化了，它并不是必须通过Spring的配置文件控制。因此通过系统属性和传统的Spring Boot外部配置文件依然可以很好的支持日志控制和管理。 根据不同的日志系统，你可以按如下规则组织配置文件名，就能被正确加载： Logback： logback-spring.xml , logback-spring.groovy , logback.xml , logback.groovy Log4j： log4j-spring.properties , log4j-spring.xml , log4j.properties , log4j.xml Log4j2： log4j2-spring.xml , log4j2.xml JDK (Java Util Logging)： logging.properties SpringBoot官方推荐优先使用带有 -spring 的文件名作为你的日志配置（如使用 logback-spring.xml ，而不是 logback.xml ） 自定义输出格式在SpringBoot中可以通过在 application.properties 配置如下参数控制输出格式： logging.pattern.console：定义输出到控制台的样式（不支持JDK Logger） logging.pattern.file：定义输出到文件的样式（不支持JDK Logger） 也可以直接在日志配置文件中定义这些格式，而不是在应用配置文件中。 常用的Logback配置文件模板12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name="LOG_HOME" value="d:/logs"/&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter"/&gt; &lt;conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/&gt; &lt;conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name="CONSOLE_LOG_PATTERN" value="$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(--)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;"/&gt; &lt;!-- Console 输出设置 --&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;!--&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt;--&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/mixedSys.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 日志logger(包.类)的输出级别 --&gt; &lt;logger name="org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver" level="DEBUG" &gt; &lt;appender-ref ref="console" /&gt; &lt;appender-ref ref="file" /&gt; &lt;/logger&gt; &lt;logger name="org.springframework.boot" level="DEBUG"/&gt; &lt;!-- 为 Hibernate sql 定制 --&gt; &lt;!-- &lt;logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE" /&gt; &lt;logger name="org.hibernate.type.descriptor.sql.BasicExtractor" level="DEBUG" /&gt; &lt;logger name="org.hibernate.SQL" level="DEBUG" /&gt; &lt;logger name="org.hibernate.engine.QueryParameters" level="DEBUG" /&gt; &lt;logger name="org.hibernate.engine.query.HQLQueryPlan" level="DEBUG" /&gt; --&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level="INFO"&gt; &lt;!-- 此时debug级别的信息会被过滤 --&gt; &lt;appender-ref ref="console" /&gt; &lt;appender-ref ref="file" /&gt; &lt;/root&gt; &lt;!--日志异步到数据库 --&gt; &lt;!-- &lt;appender name="DB" class="ch.qos.logback.classic.db.DBAppender"&gt; 日志异步到数据库 &lt;connectionSource class="ch.qos.logback.core.db.DriverManagerConnectionSource"&gt; 连接池 &lt;dataSource class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;driverClass&gt;com.mysql.jdbc.Driver&lt;/driverClass&gt; &lt;url&gt;jdbc:mysql://127.0.0.1:3306/databaseName&lt;/url&gt; &lt;user&gt;root&lt;/user&gt; &lt;password&gt;root&lt;/password&gt; &lt;/dataSource&gt; &lt;/connectionSource&gt; &lt;/appender&gt; --&gt; &lt;/configuration&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[用SpringMVC搭建web应用]]></title>
      <url>%2F2016%2F12%2F13%2F%E7%94%A8SpringMVC%E6%90%AD%E5%BB%BAweb%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[在使用SpringMVC时，最重要的2个类就是DispatcherServlet和ContextLoaderListener。DispatcherServlet加载包含Web组件的bean，如控制器、视图解析器以及处理器映射，ContextLoaderListener加载应用中的其他bean(通常是驱动应用后端的中间层和数据层组件)。 Servlet 3.0之后servlet3.0规范出来后，spring3.2有了一种简便的搭建方式。直接继承AbstractAnnotationConfigDispatcherServletInitializer即可。这个类会自动创建DispatcherServlet和ContextLoaderListener。这种方式不再需要web.xml，非常方便。 原理在Servlet 3.0环境中，容器会在类路径中查找实现javax.servlet.ServletContainerInitializer接口的类，如果能发现的话，就会用它来配置Servlet容器。Spring提供了这个接口的实现，名为SpringServletContainerInitializer，这个类反过来又会查找实现WebApplicationInitializer的类并将配置的任务交给它们来完成。Spring 3.2引入了一个便利的WebApplicationInitializer基础实现，也就是AbstractAnnotationConfigDispatcherServletInitializer。所以我们只要继承AbstractAnnotationConfigDispatcherServletInitializer（同时也就实现了WebApplicationInitializer），在部署到Servlet 3.0容器中的时候，容器会自动发现它，并用它来配置Servlet上下文。 123456789101112131415public class MyWebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class&lt;?&gt;[]&#123;RootConfig.class&#125;; &#125; // 指定配置类 protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class&lt;?&gt;[]&#123;WebConfig.class&#125;; &#125; // 将DispatcherServlet映射到"/" protected String[] getServletMappings() &#123; return new String[]&#123;"/"&#125;; &#125;&#125; Servlet 3.0之前如果你要部署在不支持servlet3.0的容器，比如tomcat6和以下版本，那就只能通过web.xml来配置了。1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="2.5" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"&gt; &lt;!-- 配置根上下文 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 注册Spring监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- SpringMVC前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- contextConfigLocation配置springmvc加载的配置文件（配置处理器、映射器、适配器等等） 如果不配置contextConfigLocation，默认加载的是/WEB-INF/servlet名称- serlvet.xml（springmvc-servlet.xml） --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 指定servlet加载顺序，整数越小优先越高 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解决Linux下DNS配置重启失效问题]]></title>
      <url>%2F2016%2F12%2F02%2F%E8%A7%A3%E5%86%B3Linux%E4%B8%8BDNS%E9%85%8D%E7%BD%AE%E9%87%8D%E5%90%AF%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[有时候能ping通ip地址，却ping不通域名，这就是dns没有配置的缘故。但是DNS配置文件 /etc/resolv.conf 每次重启就会失效。 那么问题来了，怎么解决每次都要配置的问题呢？Ubuntu系统下打开这个配置文件，发现有注释提示： # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)# DO NOT EDIT THIS FILE BY HAND — YOUR CHANGES WILL BE OVERWRITTEN 原来系统已经提示我们不要手动改此文件，因为这里每次重启会被覆盖。 方法1 执行sudo vim /etc/network/interfaces 添加一行DNS配置，比如dns-nameservers 8.8.8.8 方法2 执行sudo vim /etc/resolvconf/resolv.conf.d/base 添加DNS配置，比如nameserver 8.8.8.8 如果有多个DNS就添加多行，一行一个 保存后执行resolvconf -u此时，再打开/etc/resolv.conf会发现刚才添加的DNS配置了。 CentOS系统下直接编辑/etc/resolv.conf，重启之后一样会失效。 方法：直接将DNS配置写入网卡中 执行 cd /etc/sysconfig/network-scripts/ 编辑网卡配置文件 vi ifcfg-eth0，在后面加入DNS配置 DNS1=223.5.5.5DNS1=223.6.6.6 重启网卡service network restart即可此时，再打开/etc/resolv.conf会发现刚才添加的DNS配置了。以后在重启就没问题了 ^_^]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux虚拟机设置静态IP]]></title>
      <url>%2F2016%2F11%2F15%2FLinux%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81IP%2F</url>
      <content type="text"><![CDATA[照着网上的方法试了，总有几个步骤不对，反复试了几次，终于成功了，做下笔记。 环境我是win7系统（这个无所谓），本地VMWare装了Ubuntu 16.04 LTS 64位虚拟机。想在win7用xshell操作本地虚拟机。 设置方法配置VMware网络环境VMware在默认安装完成之后，会创建三个虚拟的网络环境： VMnet0 ：桥接网络 VMnet1 ：Host-only VMnet8 ：NAT 其中，NAT表示VMWware内安装的Ubuntu将会在一个子网中，VMware通过网络地址转换，通过物理机的IP上网。我们选择NAT方式实现Ubuntu的静态IP地址配置。 打开VMware，在顶部依次选择：编辑 &gt; 虚拟网路编辑器，打开虚拟网路编辑器： 去掉VMnet0和VMnet1，只保留VMnet8。 然后，去掉如下图中的“使用本地DHCP服务奖IP地址分配给虚拟机”： 这里的子网IP为：192.168.8.0，子网掩码为：255.255.255.0，因此，在Ubuntu中，设置IP地址的时候，可以设置为192.168.8.x，x可以为1~255。 选择“NAT设置”，打开NAT设置面板：查看自己的网关地址，例如，此处的网关应该为：192.168.8.2。 最后，在VMWare的虚拟机管理界面，选择Ubuntu的“编辑虚拟机设置”，打开Ubuntu这个虚拟的设置界面。 选择网络适配器，然后确定网络连接选中的是“自定义”中的VMnet8(NAT模式)： VMWare设置完毕。 Ubuntu网络设置 在Ubuntu桌面的右上角，点击网络图标，然后选择“Edit Connections”： 点击Edit按钮，在IPv4Settings选项卡中，Method选择Manual，点击add，编辑ip地址设置的IP地址为： IP： 192.168.8.100 子网掩码： 255.255.255.0 网关： 192.168.8.2然后保存。 最后，点击Ubuntu桌面右上角的网络图标，选择Disconnect，断开连接。然后再打开该菜单，选择Connect，即可连接上网。 终端配置打开Terminal，配置静态ip sudo vi /etc/network/interfaces 内容改为如下：12345678auto lo iface lo inet loopbackauto ens33 iface ens33 inet static address 192.168.8.100 netmask 255.255.255.0 gateway 192.168.8.2 这边说明一下，ubuntu15开始，网卡名eth0改成了ens33。 配置dns sudo vi /etc/resolv.conf 在里面填入DNS，比如阿里的dns：223.5.5.51nameserver 223.5.5.5 设置完毕。 总结有的网上说要执行sudo /etc/init.d/networking restart重启网络。但是我们之前vmware设置选择自定义的nat模式，所以执行以上命令会出错，只要vmware改为桥接模式直接连接物理网络，勾选复制物理网络连接状态，在执行就可以。 但是这样会导致虚拟机连不到网络，所以我最后又将连接模式改为自定义NAT模式，发现这时候，主机可以ssh连接本地虚拟机了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis入门]]></title>
      <url>%2F2016%2F11%2F11%2FRedis%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[redis官方不支持windows系统，所以我将redis装在linux下。我用的Ubuntu 16 64位系统。 安装Redis sudo apt-get install redis-server 非常方便，一句话搞定。 配置Redis由于要远程连接Redis，所以要修改Redis的默认配置文件。修改/etc/redis/redis.conf，把bind 127.0.0.1注释掉即可 # bind 127.0.0.1 启动和关闭Redis服务如果是用apt-get或者yum install安装的redis，可以直接通过下面的命令停止/启动/重启： /etc/init.d/redis-server stop/etc/init.d/redis-server start/etc/init.d/redis-server restart 如果是通过源码安装的redis，则可以通过redis的客户端程序redis-cli的shutdown命令来重启redis： redis-cli -h 127.0.0.1 -p 6379 shutdown 如果上述方式都没有成功停止redis，则可以使用终极武器 kill -9直接杀进程。 Redis数据类型redis有5种数据类型： string（字符串） hash（哈希） list（列表） set（集合） zset（sorted set：有序集合） stringstring是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。string类型是Redis最基本的数据类型，一个键最大能存储512MB。 hashRedis hash 是一个键值对集合。Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 listRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 setRedis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 zsetRedis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 Java操作Redis引入redis驱动包12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 创建连接1234Jedis jedis = new Jedis("192.168.1.185");System.out.println("Connection to server sucessfully");//查看服务是否运行System.out.println("Server is running: " + jedis.ping()); 看到如下输出，说明连接成功 Connection to server sucessfullyServer is running: PONG]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HTTP协议学习笔记]]></title>
      <url>%2F2016%2F11%2F08%2FHTTP%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[HTTP基本概念 HTTP是Hyper Text Transfer Protocol（超文本传输协议）的缩写。 HTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。 HTTP是一个无状态的协议。 在TCP/IP协议栈中的位置HTTP协议通常承载于TCP协议之上，有时也承载于TLS或SSL协议层之上，这个时候，就成了我们常说的HTTPS。如下图所示：默认HTTP的端口号为80，HTTPS的端口号为443。 HTTP的请求响应模型HTTP协议永远都是客户端发起请求，服务器回送响应。见下图： 这样就限制了使用HTTP协议，无法实现在客户端没有发起请求的时候，服务器将消息推送给客户端。HTML5定义了WebSocket协议，它实现了浏览器与服务器全双工通信(full-duplex)，可以借助它实现服务器向客户端推送消息。 HTTP工作流程一次HTTP操作称为一个事务，其工作过程可分为四步： 首先客户机与服务器需要建立连接。只要单击某个超级链接，HTTP的工作开始。 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可能的内容。 服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。 客户端接收服务器所返回的信息通过浏览器显示在用户的显示屏上，然后客户机与服务器断开连接。如果在以上过程中的某一步出现错误，那么产生错误的信息将返回到客户端，有显示屏输出。对于用户来说，这些过程是由HTTP自己完成的，用户只要用鼠标点击，等待信息显示就可以了。 方法HTTP支持几种不同的的请求命令，成为 HTTP方法。每一个请求报文中都包含一个方法，告诉服务器执行什么动作。 常见http方法 描述 GET 向特定的资源发出请求，获取指定资源 POST 发送客户端数据到服务器（如表单提交） DELETE 从服务器删除指定资源 PUT 向服务器指定资源上传最新数据（完整替换数据） PATCH 向服务器指定资源上传最新数据（局部更新数据） 此外，还有head，trace，options等。 状态码当服务器收到请求，返回的响应报文中会带有一个3位数字的状态码，告诉客户端请求是否成功。状态码分5类： 整体范围 已定义范围 描述 100-199 100-101 信息提示 200-299 200-206 成功 300-399 300-305 重定向 400-499 400-415 客户端错误 500-599 500-505 服务器错误 常见的状态：200表示成功； 302表示重定向；404表示找不到资源。 HTTP报文报文格式报文是具有固定格式的数据块，由3部分组成： 对报文进行描述的起始行（start line） 包含属性的首部块（header） 可选的，包含数据的主体部分（body） 请求报文格式1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 响应报文格式1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; 只有起始行不同，主体是可选的。下图是一个报文例子： Content-Type 字段头信息必须是 ASCII 码，后面的数据可以是任何格式。因此，服务器回应的时候，必须告诉客户端，数据是什么格式，所以有了Content-Type这个字段。常见的类型: text/plain text/html text/css image/jpeg image/png video/mp4 audio/mp4 application/javascript application/json 这些数据类型总称为MIME type，每个值包括一级类型和二级类型，之间用斜杠分隔。除了预定义的类型，厂商也可以自定义类型： application/vnd.debian.binary-package 上面的类型表明，发送的是Debian系统的二进制数据包。MIME type还可以在尾部使用分号，添加参数。 Content-Type: text/html; charset=utf-8 上面的类型表明，发送的是网页，而且编码是UTF-8。客户端请求的时候，可以使用Accept字段声明自己可以接受哪些数据格式。 Accept: / 上面代码中，客户端声明自己可以接受任何格式的数据。MIME type不仅用在HTTP协议，还可以用在其他地方，比如HTML网页。123&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;&lt;!-- 等同于 --&gt;&lt;meta charset=&quot;utf-8&quot; /&gt; Content-Encoding 字段由于发送的数据可以是任何格式，因此可以把数据压缩后再发送。Content-Encoding字段说明数据的压缩方法。 Content-Encoding: gzip Content-Encoding: compress Content-Encoding: deflate 客户端在请求时，用Accept-Encoding字段说明自己可以接受哪些压缩方法。 Accept-Encoding: gzip, deflate 参考资料：《HTTP权威指南》阮一峰-http入门]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Hexo搭建个人博客]]></title>
      <url>%2F2016%2F10%2F27%2F%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
      <content type="text"><![CDATA[最近闲着没事，用hexo搭建了一个个人博客，部署在 github 和 oschina上，欢迎大家来我博客踩踩~ ^_^ 下面总结一下搭建过程： 环境搭建hexo是一个简单地、轻量地、基于Node的一个静态博客框架，可以方便的生成静态网页托管在github和Heroku上引用Hexo作者 @tommy351 的话： 快速、简单且功能强大的 Node.js 博客框架。A fast, simple &amp; powerful blog framework, powered by Node.js. 所以，第一步，就是下载node的安装包并安装，附上node下载地址。安装好node，会默认一起安装好npm包管理器，这可是一个神器啊。可以打开终端cmd，执行一下命令确认安装完毕。 node -vnpm -version 另外一个，就是git了。git也没什么好说的，官网下载，选择自己操作系统的版本，一路next就装好了。 安装hexo在git终端或者cmd执行安装hexo npm install hexo-cli -g 以windows系统为例，在你想要安装的盘新建一个目录，比如d:/blog,在此目录下右键打开git的终端(就是Git Bash Here),然后执行 hexo init 初始化博客目录，然后执行 npm install 会下载需要的库。之后执行 hexo server 简便语法：hexo s启动本地服务器，在浏览器打开localhost:4000就可以看到效果了。关闭本地服务：ctrl + c有不明白可以看hexo官网,官网讲的很详细了。 创建Github仓库本地博客搭建完，只要部署在github上就ok啦。 登录github，没有的自己注册。 创建一个Repository，名字必须为【你的用户名.github.io】。 配置博客部署信息博客的根目录d:/blog下有一个配置文件_config.yml，这里可以配置你的github的地址等信息，配置完，执行 hexo g 生成静态文件，然后 hexo d 就部署到github上了，然后在浏览器打开 【你的用户名.github.io】就可以了。 最后这个过程你会遇到许多问题，这边放上几篇参考，可以解决你的困惑。 http://www.jianshu.com/p/465830080ea9 http://www.tuicool.com/articles/ueI7naV 这些不能解决你的问题，请自行google DIY博客hexo默认主题是landscape，不喜欢，可以自己替换主题，这当然需要自己配置许多东西，我用的是NexT主题，放上一点参考吧NexT官网。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[VIM编辑器的基本使用]]></title>
      <url>%2F2016%2F10%2F26%2FVIM%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[VIM的运行模式 编辑模式：等待编辑命令输入 插入模式：编辑模式下，输入 i 进入插入模式，插入文本信息，esc退出 命令模式：在编辑模式下，输入 “：” 进行命令模式 VIM 常用命令 ：q 直接退出vi ：wq保存后退出vi ，并可以新建文件 ：q! 强制退出 ：w file 将当前内容保存成某个文件 ：set number 在编辑文件显示行号 ：set nonumber 在编辑文件不显示行号 VIM命令大全 进入vi的命令 vi filename :打开或新建文件，并将光标置于第一行首 vi +n filename ：打开文件，并将光标置于第n行首 vi + filename ：打开文件，并将光标置于最后一行首 vi +/pattern filename：打开文件，并将光标置于第一个与pattern匹配的串处 vi -r filename ：在上次正用vi编辑时发生系统崩溃，恢复filename vi filename….filename ：打开多个文件，依次进行编辑 移动光标类命令 h ：光标左移一个字符 l ：光标右移一个字符 space：光标右移一个字符 Backspace：光标左移一个字符 k或Ctrl+p：光标上移一行 j或Ctrl+n ：光标下移一行 Enter ：光标下移一行 w或W ：光标右移一个字至字首 b或B ：光标左移一个字至字首 e或E ：光标右移一个字至字尾 ) ：光标移至句尾 ( ：光标移至句首 }：光标移至段落开头 {：光标移至段落结尾 nG：光标移至第n行首 n+：光标下移n行 n-：光标上移n行 n$：光标移至第n行尾 H ：光标移至屏幕顶行 M ：光标移至屏幕中间行 L ：光标移至屏幕最后行 0：（注意是数字零）光标移至当前行首 $：光标移至当前行尾 屏幕翻滚类命令 Ctrl+u：向文件首翻半屏 Ctrl+d：向文件尾翻半屏 Ctrl+f：向文件尾翻一屏 Ctrl＋b；向文件首翻一屏 nz：将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部。 插入文本类命令 i ：在光标前 I ：在当前行首 a：光标后 A：在当前行尾 o：在当前行之下新开一行 O：在当前行之上新开一行 r：替换当前字符 R：替换当前字符及其后的字符，直至按ESC键 s：从当前光标位置处开始，以输入的文本替代指定数目的字符 S：删除指定数目的行，并以所输入文本代替之 ncw或nCW：修改指定数目的字 nCC：修改指定数目的行 删除命令 ndw或ndW：删除光标处开始及其后的n-1个字 do：删至行首 d$：删至行尾 ndd：删除当前行及其后n-1行 x或X：删除一个字符，x删除光标后的，而X删除光标前的 Ctrl+u：删除输入方式下所输入的文本 搜索及替换命令 /pattern：从光标开始处向文件尾搜索pattern ?pattern：从光标开始处向文件首搜索pattern n：在同一方向重复上一次搜索命令 N：在反方向上重复上一次搜索命令 ：s/p1/p2/g：将当前行中所有p1均用p2替代 ：n1,n2s/p1/p2/g：将第n1至n2行中所有p1均用p2替代 ：g/p1/s//p2/g：将文件中所有p1均用p2替换 选项设置 all：列出所有选项设置情况 term：设置终端类型 ignorance：在搜索中忽略大小写 list：显示制表位(Ctrl+I)和行尾标志（$) number：显示行号 report：显示由面向行的命令修改过的数目 terse：显示简短的警告信息 warn：在转到别的文件时若没保存当前文件则显示NO write信息 nomagic：允许在搜索模式中，使用前面不带“\”的特殊字符 nowrapscan：禁止vi在搜索到达文件两端时，又从另一端开始 mesg：允许vi显示其他用户用write写到自己终端上的信息 最后行方式命令 ：n1,n2 co n3：将n1行到n2行之间的内容拷贝到第n3行下 ：n1,n2 m n3：将n1行到n2行之间的内容移至到第n3行下 ：n1,n2 d ：将n1行到n2行之间的内容删除 ：w ：保存当前文件 ：e filename：打开文件filename进行编辑 ：x：保存当前文件并退出 ：q：退出vi ：q!：不保存文件并退出vi ：!command：执行shell命令command ：n1,n2 w!command：将文件中n1行至n2行的内容作为command的输入并执行之，若不指定n1，n2，则表示将整个文件内容作为command的输入 ：r!command：将命令command的输出结果放到当前行 更多使用参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OkHttp的基本使用——替代Apache HttpClient]]></title>
      <url>%2F2016%2F10%2F26%2FOkHttp%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E2%80%94%E2%80%94%E6%9B%BF%E4%BB%A3Apache%20HttpClient%2F</url>
      <content type="text"><![CDATA[http是现在主流应用使用的网络请求方式, 用来交换数据和内容, 有效的使用HTTP可以使你的APP 变的更快和减少流量的使用。 OkHttp 是一个很棒HTTP客户端: 支持SPDY, 可以合并多个到同一个主机的请求 使用连接池技术减少请求的延迟(如果SPDY是可用的话) 使用GZIP压缩减少传输的数据量 缓存响应避免重复的网络请求 OkHttp可以替换Apache的HttpClientOkHttp支持2.3和以上版本，对于java，需要jdk1.7 ，OkHttp需要依赖Okio包 下面上demo 使用get方式请求，获取响应123456789101112131415161718192021222324import java.io.IOException;import okhttp3.OkHttpClient;import okhttp3.Request;import okhttp3.Response;public class GetExample &#123; OkHttpClient client = new OkHttpClient(); String run(String url) throws IOException &#123; Request request = new Request.Builder() .url(url) .build(); try (Response response = client.newCall(request).execute()) &#123; return response.body().string(); &#125; &#125; public static void main(String[] args) throws IOException &#123; GetExample example = new GetExample(); String response = example.run("https://raw.github.com/square/okhttp/master/README.md"); System.out.println(response); &#125;&#125; 使用post向服务器发送请求12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.IOException;import okhttp3.MediaType;import okhttp3.OkHttpClient;import okhttp3.Request;import okhttp3.RequestBody;import okhttp3.Response;public class PostExample &#123; public static final MediaType JSON = MediaType.parse("application/json; charset=utf-8"); OkHttpClient client = new OkHttpClient(); String post(String url, String json) throws IOException &#123; RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); try (Response response = client.newCall(request).execute()) &#123; return response.body().string(); &#125; &#125; String bowlingJson(String player1, String player2) &#123; return "&#123;'winCondition':'HIGH_SCORE'," + "'name':'Bowling'," + "'round':4," + "'lastSaved':1367702411696," + "'dateStarted':1367702378785," + "'players':[" + "&#123;'name':'" + player1 + "','history':[10,8,6,7,8],'color':-13388315,'total':39&#125;," + "&#123;'name':'" + player2 + "','history':[6,10,5,10,10],'color':-48060,'total':41&#125;" + "]&#125;"; &#125; public static void main(String[] args) throws IOException &#123; PostExample example = new PostExample(); String json = example.bowlingJson("Jesse", "Jake"); String response = example.post("http://www.roundsapp.com/post", json); System.out.println(response); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Oracle入门]]></title>
      <url>%2F2016%2F10%2F25%2FOracle%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[今天学习了Oracle的基本使用，做下总结： 基本操作以Oracle 11g为例，安装好以后，普通账户都是未解锁的，不能使用，只能使用超级管理员登录。 sqlplus / as sysdba 这样就用超级管理员登录了，无需密码。然后解锁普通用户之后，就可以使用使用普通用户了。举例： – – 解锁用户 scottalter user scott account unlock;– – 设置密码为 tigeralter user scott identified by tiger;– – 退出登录exit– – 使用普通用户 scott 登录sqlplus scott/tiger 普通用户修改密码，需要验证旧密码，然后根据提示修改即可。 password 查询当前用户是谁 show user; 查询scott用户下的所有对象（表），使用tab表，tab表每个用户都有 select * from tab; 设置显示的列宽（字符型varchar2、日期型date），10个宽度位，a表示字符型，大小写均可 column ename format a12; 设置显示的列宽（数值型number），9表示数字型，一个9表示一个数字位，四个9表示四个数字位，只能用9 column empno format 9999; 设置一页显示60条记录的高度 set pagesize 60; 使用/杠，执行最近一次的SQL语句 / 清屏，属于SQL*PLUS工具中的命令 host cls; 查询emp表的结构 desc emp; 使用dual哑表或者伪表，使用字符串连接符号||，输出”hello world”，在oracle中from是必须写的 select ‘hello’ || ‘ world’ “结果” from dual; 使用sysdate，显示系统当前时间，在默认情况下，oracle只显示日期，而不显示时间，格式：26-4月-15 select sysdate from dual; 使用spool命令，保存SQL语句到硬盘文件e:/oracle-day01.sql，并创建sql文件 spool e:/oracle-day01.sql; 使用spool off命令，保存SQL语句到硬盘文件e:/oracle-day01.sql，并创建sql文件，结束语句 spool off; 使用@命令，将硬盘文件e:/crm.sql，读到orcl实例中，并执行文件中的sql语句 @ e:/crm.sql; 使用--符号，设置单行注释 使用/* */符号，设置多行注释 总结SQL语句的特点 是SQL92/99的ANSI官方标准，只要按照该标准来写，在任何的关系型数据库中都可以直接执行 SQL语句的关健字不能简写，例如：select，where，from 大小写不敏感，提倡大写 能够对表数据进行增删改查操作 必须以分号结束 通常称做语句 SQLPLUS命令的特点 是oracle自带的一款工具，在该工具中执行的命令叫SQLPLUS命令 SQLPLUS工具的命令中的关健字可以简写，也可以不简写，例如：col ename for a10; 大小写不敏感，提倡大写 不能够对表数据进行增删改查操作，只能完成显示格式控制，例如：设置显示列宽，清屏，记录执行结果 可以不用分号结束，也可以用分号结束，个人提倡不管SQL或SQLPLUS，都以分号结束 通常称做命令，是SQLPLUS工具中的命令注意：SQLPLUS命令是SQLPLUS工具中特有的语句 单引号出现的地方如下： 字符串型，例如：’hello’ || ‘ world’ 日期型，例如’25-4月-15’ 双引号出现的地方如下： 列别名，例如：sal12 “年 薪”，或 sal12 年薪，个人提倡用&quot;&quot;双引号作列别名]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker安装与基础命令]]></title>
      <url>%2F2016%2F10%2F25%2FDocker%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[Docker安装我是在Ubuntu 16上安装的docker，linux安装docker只需要一个命令： sudo apt-get install docker.io 运行完后，可以在终端输入docker看到以下信息证明我们安装成功了注：提示权限问题就添加sudo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566dockerUsage: docker [OPTIONS] COMMAND [arg...] docker daemon [ --help | ... ] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify Use TLS and verify the remote -v, --version Print version information and quitCommands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on a container or image kill Kill a running container load Load an image from a tar archive or STDIN login Register or log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container network Manage Docker networks pause Pause all processes within a container port List port mappings or a specific mapping for the CONTAINER ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart a container rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save an image(s) to a tar archive search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop a running container tag Tag an image into a repository top Display the running processes of a container unpause Unpause all processes within a container update Update resources of one or more containers version Show the Docker version information volume Manage Docker volumes wait Block until a container stops, then print its exit codeRun 'docker COMMAND --help' for more information on a command. 安装完以后，也可运行以下命令查看版本信息： docker -vdocker versiondocker info 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maven学习笔记（3） --- 生命周期]]></title>
      <url>%2F2016%2F10%2F25%2FMaven%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89%20---%20%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
      <content type="text"><![CDATA[Maven的3个生命周期：Maven的生命周期就是对所有的构建过程进行抽象和统一。包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等几乎所有的构建步骤。 Maven的生命周期是抽象的，即生命周期不做任何实际的工作，实际任务由插件完成，类似于设计模式中的模板方法。每个生命周期包含一些阶段（phase），阶段是有顺序的，后面的阶段依赖于前面的阶段。 clean生命周期：清理项目，phase如下。 pre-clean：执行清理前需要完成的工作 clean：清理上一次构建生成的文件 post-clean：执行清理后需要完成的工作 default生命周期：构建项目，phase如下。 validate：验证工程是否正确，所有需要的资源是否可用。 initialize：初始化 generate-sources： process-sources：处理资源文件 【src/main/resources】 generate-resources： process-resources： compile：编译项目的源代码。【src/main/java】 process-classes：处理编译后的class文件 generate-test-sources： process-test-sources：处理测试资源文件【src/test/resources】 generate-test-resources： process-test-resources： test-compile：编译测试文件【src/test/java】 process-test-classes：处理编译后的测试class文件 test：使用单元测试框架来测试已编译的源代码。测试代码不会被打包或布署。 pre-package：打包之前要做的准备工作 package：把已编译的代码打包成可发布的格式，比如jar。 pre-integration-test： integration-test：如有需要，将包处理和发布到一个能够进行集成测试的环境。 post-integration-test： verify：运行所有检查，验证包是否有效且达到质量标准。 install：把包安装到maven本地仓库，可以被其他工程作为依赖来使用。 deploy：在集成或者发布环境下执行，将最终版本的包拷贝到远程的repository，使得其他的开发者或者工程可以共享。 site生命周期：建立和发布项目站点，phase如下。 pre-site：生成项目站点之前需要完成的工作 site：生成项目站点文档 post-site：生成项目站点之后需要完成的工作 site-deploy：将项目站点发布到服务器 命令行与生命周期 mvn clean ：调用clean生命周期的clean阶段，实际执行pre-clean和clean阶段。 mvn test：调用default生命周期的test阶段，实际执行test以及之前所有阶段。 mvn clean install：调用clean生命周期的clean阶段和default的install阶段，实际执行pre-clean和clean，install以及之前所有阶段。 mvn clean deploy site-deploy：调用clean生命周期的clean阶段，default生命周期的deploy阶段和site生命周期的site-deploy阶段。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maven学习笔记（2） --- 依赖]]></title>
      <url>%2F2016%2F10%2F25%2FMaven%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%20---%20%E4%BE%9D%E8%B5%96%2F</url>
      <content type="text"><![CDATA[maven依赖在maven项目中，我们会在pom.xml文件中引入我们需要用到的依赖，一般用groupId,artifactId,version就够了，如下：12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 有时，也会指定依赖范围，比如：123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; maven有3套classpath，编译classpath，运行classpath，测试classpath。 依赖范围依赖范围有以下几种： compile 编译依赖范围。默认是这种范围。对3种classpath都有效。典型例子是spring-core，在编译，运行，测试时都需要。 test 测试依赖范围。只对测试classpath有效。典型例子是junit，它只在测试期间需要。 provided 已提供依赖范围。对编译classpath和测试classpath有效，运行classpath无效。典型例子是servlet-api，运行的时候容器会提供，所以运行时不需要。 runtime 运行时依赖范围。对运行classpath和测试classpath有效。典型例子是jdbc驱动实现，编译的时候只要有jdk的jdbc接口即可。 system 系统依赖范围。和provided一样，对3种classpath都有效。但是，使用时必须通过systemPath元素显式指定依赖文件的路径。限制比较多，一般不使用。 import 导入依赖范围。对3种classpath都没实际影响。 依赖机制 依赖会传播：A依赖B，B依赖C，那么maven解析的时候会找到B，发现B依赖C，又去把C引入，然后在引入B 有相同依赖的时候，优先选路径最近的：比如A-&gt;B-&gt;C-&gt;X(1.0), A-&gt;D-&gt;X(2.0),这时候有2个X，会冲突，maven会选择最近的，也就是X(2.0) 在依赖路径长度相同时，优先选先声明的：比如A-&gt;B-&gt;Y(1.0), A-&gt;C-&gt;Y(2.0),在maven2.0.9之后，maven会选在pom中先声明的那个。即如果C的依赖声明在B之前，就选Y(2.0)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maven学习笔记（1） --- 仓库]]></title>
      <url>%2F2016%2F10%2F25%2FMaven%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%20---%20%E4%BB%93%E5%BA%93%2F</url>
      <content type="text"><![CDATA[maven坐标maven的构件（jar包）是根据坐标来确定其在仓库的保存位置的。maven的坐标是通过以下元素来定义的： groupId : 一般是当前项目的公司名和项目组 artifactId : 项目名称 version : 项目版本 packaging : 打包方式，默认是jar,也可以是war classifier : 定义构建输出的一些附属构件，不常用 形如1234&lt;groupId&gt;com.company.group&lt;/groupId&gt;&lt;artifactId&gt;MyApp&lt;/artifactId&gt;&lt;packaging&gt;war&lt;/packaging&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; maven仓库顾名思义，仓库就是存放依赖（jar包）的地方。maven仓库分为本地仓库，中央仓库，远程仓库，和私服4种。 本地仓库通俗的说，本地仓库就是我们本地电脑中的一个文件夹，用来存放jar包的仓库。本地仓库的默认位置：无论是Windows还是Linux，在用户的目录下都有一个.m2/repository/的仓库目录。可通过修改maven安装目录下的settings.xml文件来修改本地仓库位置:&lt;localRepository&gt;D:\repo&lt;/localRepository&gt; 中央仓库中央仓库是默认的远程仓库，它包含了绝大多数流行的开源Java构件，以及源码、作者信息、SCM、信息、许可证信息等。id是central，url地址是http://repo1.maven.org/maven2 远程仓库在很多情况下，默认的中央仓库无法满足项目的需求，可能项目需要的构件存在于另外一个远程仓库中，如:JBoss，Maven仓库。这时，可以在POM中配置该仓库，比如：12345678910111213141516171819202122&lt;project&gt; ... &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jboss&lt;/id&gt; &lt;name&gt;JBoss Repository&lt;/name&gt; &lt;url&gt;http://repository.jboss.com/maven2/&lt;/url&gt; &lt;releases&gt; &lt;!-- 更新频率never,always,interval,daily --&gt; &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;!-- 检查和检验文件的策略,fail,warn,ignore --&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repositories&gt; ... &lt;/project&gt; 在repositories元素下，用repository子元素声明一个或者多个远程仓库。该例中声明了一个id为jboss，名称为JBoss Repository的仓库。任何一个仓库声明的id必须是唯一的，尤其需要注意的是，maven自带的中央仓库使用的id为central，如果其他的仓库声明也使用该id，就会覆盖中央仓库的配置。该配置中的url值指向了仓库的地址，一般来说，该地址都基于http协议，maven用户都可以在浏览器中打开仓库地址浏览构件。该例配置中的releases和snapshots元素比较重要，它们用来控制Maven对于发布版构件和快照版构件的下载。该例中releases的enabled值为true，表示开启JBoss仓库的发布版本下载支持，而snapshots的enabled值为false，表示关闭JBoss仓库的快照版本的下载支持。该例中的layout元素值default表示仓库的布局是Maven2及Maven3的默认布局，而不是Maven1的布局。 远程仓库的认证远程仓库默认无须认证就可访问，有时出于安全需要，可配置认证访问。配置认证信息和配置仓库信息不同，仓库信息可以直接配置在POM文件中，但是认证信息必须配置在settings.xml文件中。这是因为POM往往是被提交到代码仓库中供所有成员访问的，而settings.xml一般只放在本机。因此，settings.xml中配置认证信息更为安全。假设为id为my-proj的仓库配置认证信息，编辑settings.xml文件如下：1234567891011&lt;settings&gt; ... &lt;servers&gt; &lt;server&gt; &lt;id&gt;my-proj&lt;/id&gt; &lt;username&gt;repo-user&lt;/username&gt; &lt;password&gt;repo-pwd&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; ... &lt;/settings&gt; 注：settings.xml中server元素的id必须与POM中需要认证的repository元素的id完全一致。 私服私服是架设在局域网的特殊远程仓库。一般maven自己的中央仓库存放了主流的jar包，但是有时候自己的编写的jar包就没办法在中央仓库找到了，这时候就需要配置一个远程仓库，就是所谓的“私服”，就可以将我们自己的jar包存放到远程仓库中，这样当maven需要下载jar包的时候，就可以先请求私服，如果私服上找不到，就会从maven的中央仓库再下载，之后也会缓存在私服上供以后使用。 镜像这里另外说一下镜像。国内访问国外的仓库，你懂的，所以有必要配置镜像。在maven安装目录下的settings.xml配置文件中，可以配置镜像，在&lt;Mirrors&gt;元素中，可配置一个或多个&lt;mirror&gt;镜像。比如：123456&lt;mirror&gt; &lt;id&gt;nexus-osc&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus osc&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;&lt;/mirror&gt; mirrorOf中写的是哪个仓库的镜像，例子中表明是中央仓库的镜像，这样，一切往中央仓库的请求，都会转发到去请求这个镜像的地址。所以，mirrorOf中不能乱写。镜像也可以配置基于id的仓库认证。mirrorOf中可以写*,表示对一切的请求都会转到这个镜像。 为了满足复杂的规则，maven支持高级的镜像配置： &lt;mirrorOf&gt;*&lt;mirrorOf&gt;: 匹配所有仓库 &lt;mirrorOf&gt;external:*&lt;mirrorOf&gt;: 匹配所有不在本机上的远程仓库 &lt;mirrorOf&gt;repo1,repo2&lt;mirrorOf&gt;: 匹配repo1和repo2，多个仓库用逗号隔开 &lt;mirrorOf&gt;*,!repo3&lt;mirrorOf&gt;: 匹配所有仓库，除了repo3 *匹配所有，这个镜像建议放在最后，否则maven循环匹配，匹配到第一个就是*，满足，直接就结束了，其他镜像就不生效了。 仓库搜索在工作中，我们需要知道摸个依赖的坐标来使用，可以使用仓库搜索。附上几个常用的搜索地址： https://repository.sonatype.org/ http://mvnbrowser.com/ http://mvnrepository.com/ 最后总结：在pom中加入依赖声明后，maven会优先根据坐标去我们本地仓库查找，如果找到就用了。如果找不到，就会默认去中央仓库查找，然后下载到本地，然后使用。如果我们配置了私服或者其他远程仓库，就会从远程仓库查找，下载。如果我们有配置对应的镜像，就会从镜像下载使用了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC重定向传参数的实现]]></title>
      <url>%2F2016%2F10%2F23%2FSpringMVC%E9%87%8D%E5%AE%9A%E5%90%91%E4%BC%A0%E5%8F%82%E6%95%B0%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[在spring的一个controller中要把参数传到页面，只要配置视图解析器，把参数添加到Model中，在页面用el表达式就可以取到。但是，这样使用的是forward方式，浏览器的地址栏是不变的，如果这时候浏览器F5刷新，就会造成表单重复提交的情况。所以，我们可以使用重定向的方式，改变浏览器的地址栏，防止表单因为刷新重复提交。 jsp文件： 1234567891011121314151617181920&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;login&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form id="form1" action="/demo/user/login" method="post"&gt; 账号:&lt;input type="text" name="name" /&gt;&lt;/br&gt; 密码:&lt;input type="password" name="password" /&gt;&lt;/br&gt; &lt;input type="submit" value="submit"/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; controller：12345678910111213141516171819202122232425262728293031package com.demo.controller;import java.util.Map;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;/** * @author lpj * @date 2016年7月10日 */@Controller@RequestMapping("/user")public class DemoController &#123; @RequestMapping("/login") public String login(@RequestParam Map&lt;String, String&gt; user, Model model) &#123; System.out.println("用户提交了一次表单"); String username; if (user.get("name").isEmpty()) &#123; username = "Tom"; &#125; else &#123; username = user.get("name"); &#125; model.addAttribute("msg", username);// return "home";//此方式跳转，页面刷新会重复提交表单 return "redirect:/home.jsp"; &#125;&#125; 由于重定向相当于2次请求，所以无法把参数加在model中传过去。在上面例子中，页面获取不到msg参数。要想获取参数，可以手动拼url，把参数带在后面。Spring 3.1 提供了一个很好用的类：RedirectAttributes。 使用这个类，我们可以把参数随着重定向传到页面，不需自己拼url了。把上面方法参数中的Model换成RedirectAttributes，参数就自动跟在url后了。 但是，这样页面不能用el获取到，还要另外处理，所以，我们还有一种方式，不拼url，用el获取参数，就像普通转发一样。还是使用RedirectAttributes，但是这次不用addAttribute方法，spring为我们准备了新方法，addFlashAttribute（）。这个方法原理是放到session中，session在跳到页面后马上移除对象。所以你刷新一下后这个值就会丢失。controller代码改为如下:1234567891011121314151617181920212223242526272829303132333435363738394041package com.demo.controller;import java.util.Map;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.servlet.mvc.support.RedirectAttributes;/** * @author lpj * @date 2016年7月10日 */@Controller@RequestMapping("/user")public class DemoController &#123; @RequestMapping("/login")// public String login(@RequestParam Map&lt;String, String&gt; user, Model model) &#123; public String login(@RequestParam Map&lt;String, String&gt; user, RedirectAttributes model) &#123; System.out.println("用户提交了一次表单"); String username; if (user.get("name").isEmpty()) &#123; username = "Tom"; &#125; else &#123; username = user.get("name"); &#125; model.addFlashAttribute("msg", username);// return "home";//此方式跳转，页面刷新会重复提交表单 return "redirect:/user/toHome"; &#125; @RequestMapping("/toHome") public String home(@ModelAttribute("msg") String msg, Model model) &#123; System.out.println("拿到重定向得到的参数msg:" + msg); model.addAttribute("msg", msg); return "home"; &#125;&#125; 这边我们使用@ModelAttribute注解，获取之前addFlashAttribute添加的数据，之后就可以正常使用啦。需要例子代码的可以点此下载：demo]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot简单入门]]></title>
      <url>%2F2016%2F10%2F21%2FSpringBoot%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8%2F</url>
      <content type="text"><![CDATA[今天学学springboot，springboot是spring4新出的，目的在于减少配置，加快开发速度，springboot中内嵌了tomcat等。来看一个简单的hello world 的小demo。 新建一个maven项目 pom.xml 12345678910111213141516171819202122&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lpj&lt;/groupId&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 继承springboot --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- 添加springWeb支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 我用的是目前比较新的版本，要求jdk1.8 下面我们来输出hello world新建一个DemoController：12345678910111213141516171819202122232425package controller;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * @author lpj * @date 2016年6月10日 */@Controller@EnableAutoConfigurationpublic class DemoController &#123; @RequestMapping("/") @ResponseBody String home() &#123; return "Hello World!"; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(DemoController.class, args); &#125;&#125; @EnableAutoConfiguration是开启默认配置参数，就是之前我们pom中spring-boot-starter-parent自带的，tomcat也内嵌了，所以直接run as Java Application，就ok了。如图 然后打开浏览器，输入localhost:8080，回车，就看到结果了 PS： 在resource目录下，我们可以添加一个叫 banner.txt的文件，这样当项目启动的时候，会自动加载这个文件，在控制台输出banner.txt文件中的内容。当然，如果不想看到banner，也可以关闭，方法如下： 123456public static void main(String[] args) &#123; // SpringApplication.run(DemoController.class, args); SpringApplication application = new SpringApplication(DemoController.class); application.setShowBanner(false); application.run(args); &#125; 或者使用链式语法：1234567public static void main(String[] args) &#123; // SpringApplication.run(DemoController.class, args); // SpringApplication application = new SpringApplication(DemoController.class); // application.setShowBanner(false); // application.run(args); new SpringApplicationBuilder().showBanner(false).sources(DemoController.class).run(args); &#125; 有一点需要注意，如果run方法和controller分开放，项目入口文件【SpringApplication.run方法所在的那个类】所在的包名，必须要是controller，service，entity等等的包名的上级目录，否则会导致项目启动后无法正确显示显示页面。因为SpringApplication.run()启动时，会扫面同目录以及子目录下的@Controller，@Service，@Repository，@Componet等注解标识的类，如果不在目录不是父子关系，会识别不到，导致问题出现。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hibernate Validator学习笔记]]></title>
      <url>%2F2016%2F10%2F21%2FHibernate%20Validator%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[Hibernate Validator 是 Bean Validation 的参考实现 。Hibernate Validator 提供了 JSR 303 规范中所有内置 constraint 的实现，除此之外还有一些附加的 constraint。在日常开发中，Hibernate Validator经常用来验证bean的字段，基于注解，方便快捷高效。 Bean Validation 中内置的 constraint 注解 作用 @Valid 被注释的元素是一个对象，需要检查此对象的所有字段值 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max, min) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(value) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint 注解 作用 @Email 被注释的元素必须是电子邮箱地址 @Length(min=, max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=, max=) 被注释的元素必须在合适的范围内 @NotBlank 被注释的字符串的必须非空 @URL(protocol=,host=, port=, regexp=, flags=) 被注释的字符串必须是一个有效的url @CreditCardNumber 被注释的字符串必须通过Luhn校验算法，银行卡，信用卡等号码一般都用Luhn计算合法性 @ScriptAssert(lang=, script=, alias=) 要有Java Scripting API 即JSR 223 (“Scripting for the JavaTM Platform”)的实现 @SafeHtml(whitelistType=, additionalTags=) classpath中要有jsoup包 hibernate补充的注解中，最后3个不常用，可忽略。主要区分下@NotNull,@NotEmpty,@NotBlank 3个注解的区别： @NotNull：任何对象的value不能为null @NotEmpty：集合对象的元素不为0，即集合不为空，也可以用于字符串不为null @NotBlank：只能用于字符串不为null，并且字符串trim()以后length要大于0 举个使用的例子：123456789101112131415161718192021222324252627282930public class User &#123; @NotBlank private String name; //年龄要大于18岁 @Min(18) private int age; @Email private String email; //嵌套验证 @Valid private Product products; ... //省略getter，setter &#125; public class Product &#123; @NotBlank private String name; //价格在10元-50元之间 @Range(min=10,max=50) private int price; ... //省略getter，setter &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用JPress快速搭建系统]]></title>
      <url>%2F2016%2F10%2F17%2F%E4%BD%BF%E7%94%A8JPress%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E7%B3%BB%E7%BB%9F%2F</url>
      <content type="text"><![CDATA[JPress，一个wordpress的java代替版本，使用JFinal开发。支持类似wordpress的几乎所有功能，比如：模板，插件等。同时在模板上，JPress提出了“模板即模型”的概念，方便模板制作人灵活制作业务模型，移除了widget等繁杂功能，同时在模板和插件制作上比wordpress更加灵活简洁。具体介绍见 官网 下载JPress首先下载jpress，附上地址：https://github.com/JpressProjects/jpress下载完成后，解压出来，如图 导入JPress导入项目，我们只要导入jpress即可，第一个请忽略，我这边使用的eclipse，如图 安装JPress在项目上右击，run as -&gt; maven install 安装jpress，成功后如图 安装过程maven如果报错需要jdk版本，可以参考此 解决方案 启动JPress在项目上右击，run as -&gt; run configurations，在左侧Maven Build右键，new一个build脚本 [1] 名字随意起一个 [2] 选择workspace中的jpress-web模块 [3] 名字随意，建议后面带上-war，表示打包成war [4] 建议勾上 然后apply，之后run 看到server启动后，浏览器中输入 localhost:8080，看到如下图 配置数据库点击上图的链接，即可开始配置在配置之前，需要先在MySQL数据库中建好数据库，与配置的名字一致，数据库地址就写本地127.0.0.1。之后就下一步，配置登录账号密码，即可完成。此处根据提示，配置好没有自动刷新，可到eclipse后台，把server停了，在启动一下，页面就会刷新，可以登录了。 管理自己的后台首页会看到我们自己定义的名字，这时候，要进入后台去发表文章等操作，在网址处输入http://localhost:8080/jpress-web/你的登录名 ，即可进入后台。例如，我用户名为admin，所以我输入http://localhost:8080/jpress-web/admin 即可进入后台进行操作了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maven报错Please ensure you are using JDK 1.4 or above and not a JRE解决方法]]></title>
      <url>%2F2016%2F10%2F17%2FMaven%E6%8A%A5%E9%94%99Please%20ensure%20you%20are%20using%20JDK%201.4%20or%20above%20and%20not%20a%20JRE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[在eclipse下用maven编译时，可能报以下提示 Please ensure you are using JDK 1.4 or above and not a JRE (the com.sun.tools.javac.Main class is required). 原因：eclipse默认是使用jre作为运行环境，而maven编译需要jdk作为运行环境。因此，我们只要设置为jdk即可。 具体步骤： window -&gt; preferences -&gt; Java -&gt; installed jres，点击add，新加一个环境，设为默认环境，注意location选择为你的jdk目录。 之后，在你的项目上右击，build path -&gt; configure build path，编辑JRE System Library，选择刚才新建的默认环境 这样就解决问题了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用VMWare WorkStation安装Linux Mint]]></title>
      <url>%2F2016%2F10%2F17%2F%E4%BD%BF%E7%94%A8VMWare%20WorkStation%E5%AE%89%E8%A3%85Linux%20Mint%2F</url>
      <content type="text"><![CDATA[Mint是Linux的一个衍生版，基于Ubuntu，是一款开源的桌面版Linux系统，适合新手学习Linux。同时，也带有集成了媒体播放的功能，对于不玩游戏的人来说也是OK的。下面我们来安装这个系统。如果想要直接装在物理机上，可以在官网下载好iso镜像文件后，刻录在u盘中，与普通windows系统安装一样。PS：官网地址 https://www.linuxmint.com/download.php我这边选择安装在VMWare12虚拟机上。 打开VMWare，选择新建虚拟机 选择典型安装，这边选择下载好的iso文件，会提示不识别系统版本，没关系，下一步 确认系统版本，如图 然后给系统起个名字，选择安装的位置，然后下一步 分配容量，20G够了，就默认选项，下一步，完成 此时，虚拟机配置好了，接下来开始安装，先点左边的开启虚拟机 此时进入到安装桌面，点击桌面的install开始安装 稍等一会，等他加载完成，先选择语言，这个随意，拉到底，可以选简体中文 安装类型，由于我装虚拟机，所以不能清除磁盘，选其他，如果直接装物理机，则默认安装即可 然后点击新建分区，选中空闲分区，点击小+号，添加交换空间，分配1G 继续分配剩下的，作为主分区，格式一般选ext4（个人习惯，xfs，btrf也可以），挂载点选 / 点击现在安装，设置地点，键盘布局，就默认好了，键盘习惯用英语（美国），然后设置个人用户名，密码，之后就开始安装系统了。安装过程会比较久，其中下载语言包这部可以skip，节约时间，其他就不用操作，等着就好了。说LinuxMint是开箱即用的系统，不无道理，系统装完后，flash、Java就已预装，虽然只是两个小程序，但这样的设计为用户节省了宝贵的时间。同时，Mint也自带了图片查看器，音乐播放器，视频播放器，办公软件，邮箱系统等等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于VBA Excel开发中连接MySQL数据库的问题]]></title>
      <url>%2F2016%2F10%2F15%2F%E5%85%B3%E4%BA%8EVBA%20Excel%E5%BC%80%E5%8F%91%E4%B8%AD%E8%BF%9E%E6%8E%A5MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[这两天把Access移植到MySQL上，遇到个问题，始终报错说—–80004005 - 未找到数据源名称并且未指定默认驱动程序。于是上网查，折腾了一整天，最后发现原来是odbc的驱动的问题。我电脑是64位的，要用64bit的odbc数据源来配置，不能直接在控制面板下的管理工具中配。直接配的后果就是excel中找不到。 做法就是：运行 C:\Windows\SysWOW64\odbcad32.exe，在这里配，就解决问题了。还有就是，我用64位的odbc驱动竟然没有这个选项，用32位却成功了。最后得出一个结论，office是x86还是x64无所谓，但是MySQL与odbc驱动的版本一定要配套，不然容易出错。在vba代码中，驱动名一定要与配置odbc数据源的名字相同，不然也会找不到。最后贴出我的代码，供大家参考下。123456789101112131415Sub connMySql() Dim conn As ADODB.Connection Dim rs As ADODB.Recordset Dim SQL As String Set conn = New ADODB.Connection sevip = "localhost" '主机IP Db = "loandb" '将插入的 DataBase user = "root" pwd = "admin" conn.Open "DRIVER=&#123;MySQL ODBC 5.3 Unicode Driver&#125;;SERVER=" &amp; sevip &amp; ";Database=" &amp; Db &amp; ";Uid=" &amp; user &amp; ";PWD=" &amp; pwd conn.Execute "create table test2(name text,pass text)" conn.CloseEnd Sub]]></content>
    </entry>

    
  
  
</search>
